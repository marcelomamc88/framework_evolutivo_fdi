{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from river.utils import numpy2dict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from river import datasets\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Accept' : 'application/json', 'Content-Type' : 'application/json'}\n",
    "\n",
    "def send(endpoint, params_dict = {}, url='http://127.0.0.1:5001/classifier'):\n",
    "    return requests.get(url+endpoint, data=json.dumps(params_dict), headers=headers).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      region-centroid-col  region-centroid-row  short-line-density-5  \\\n0                     218                  178              0.111111   \n1                     113                  130              0.000000   \n2                     202                   41              0.000000   \n3                      32                  173              0.000000   \n4                      61                  197              0.000000   \n...                   ...                  ...                   ...   \n2305                   30                  102              0.000000   \n2306                  143                   24              0.000000   \n2307                   80                   72              0.000000   \n2308                   98                  133              0.000000   \n2309                   19                  147              0.000000   \n\n      short-line-density-2  vedge-mean  vegde-sd  hedge-mean  hedge-sd  \\\n0                      0.0    0.833333  0.547722    1.111109  0.544331   \n1                      0.0    0.277778  0.250924    0.333333  0.365148   \n2                      0.0    0.944448  0.772202    1.111112  1.025597   \n3                      0.0    1.722222  1.781593    9.000000  6.749488   \n4                      0.0    1.444444  1.515353    2.611111  1.925463   \n...                    ...         ...       ...         ...       ...   \n2305                   0.0    1.222222  0.118518    1.333333  0.800000   \n2306                   0.0    1.277777  0.907406    0.888888  1.140749   \n2307                   0.0    1.222223  1.003697    1.444444  1.167461   \n2308                   0.0    0.555555  0.172133    0.388889  0.327731   \n2309                   0.0    0.222222  0.074074    0.500000  0.077778   \n\n      intensity-mean  rawred-mean  rawblue-mean  rawgreen-mean  exred-mean  \\\n0          59.629630    52.444443     75.222220      51.222220  -21.555555   \n1           0.888889     0.000000      2.555556       0.111111   -2.666667   \n2         123.037040   111.888885    139.777790     117.444440  -33.444443   \n3          43.592594    39.555557     52.888890      38.333336  -12.111111   \n4          49.592594    44.222220     61.555557      43.000000  -16.111110   \n...              ...          ...           ...            ...         ...   \n2305       20.259260    20.333334     25.000000      15.444445    0.222222   \n2306      127.629630   117.666664    141.666670     123.555560  -29.888890   \n2307       59.000000    51.333332     74.444440      51.222220  -23.000000   \n2308        0.962963     0.000000      2.777778       0.111111   -2.888889   \n2309        4.148148     3.888889      6.666666       1.888889   -0.777778   \n\n      exblue-mean  exgreen-mean  value-mean  saturation-mean  hue-mean  \\\n0       46.777780    -25.222221   75.222220         0.318996 -2.040554   \n1        5.000000     -2.333333    2.555556         1.000000 -2.123254   \n2       50.222220    -16.777779  139.777790         0.199347 -2.299918   \n3       27.888890    -15.777778   52.888890         0.266914 -1.998857   \n4       35.888890    -19.777779   61.555557         0.302925 -2.022274   \n...           ...           ...         ...              ...       ...   \n2305    14.222222    -14.444445   25.000000         0.381059 -1.555097   \n2306    42.111110    -12.222222  141.666670         0.169397 -2.349252   \n2307    46.333332    -23.333334   74.444440         0.314606 -2.090221   \n2308     5.444445     -2.555556    2.777778         1.000000 -2.123254   \n2309     7.555555     -6.777778    7.000000         0.713228 -1.475643   \n\n       category  categorical_label  \n0          path                  4  \n1       foliage                  2  \n2           sky                  5  \n3          path                  4  \n4          path                  4  \n...         ...                ...  \n2305  brickface                  0  \n2306        sky                  5  \n2307     cement                  1  \n2308    foliage                  2  \n2309  brickface                  0  \n\n[2310 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region-centroid-col</th>\n      <th>region-centroid-row</th>\n      <th>short-line-density-5</th>\n      <th>short-line-density-2</th>\n      <th>vedge-mean</th>\n      <th>vegde-sd</th>\n      <th>hedge-mean</th>\n      <th>hedge-sd</th>\n      <th>intensity-mean</th>\n      <th>rawred-mean</th>\n      <th>rawblue-mean</th>\n      <th>rawgreen-mean</th>\n      <th>exred-mean</th>\n      <th>exblue-mean</th>\n      <th>exgreen-mean</th>\n      <th>value-mean</th>\n      <th>saturation-mean</th>\n      <th>hue-mean</th>\n      <th>category</th>\n      <th>categorical_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>218</td>\n      <td>178</td>\n      <td>0.111111</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>0.547722</td>\n      <td>1.111109</td>\n      <td>0.544331</td>\n      <td>59.629630</td>\n      <td>52.444443</td>\n      <td>75.222220</td>\n      <td>51.222220</td>\n      <td>-21.555555</td>\n      <td>46.777780</td>\n      <td>-25.222221</td>\n      <td>75.222220</td>\n      <td>0.318996</td>\n      <td>-2.040554</td>\n      <td>path</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>113</td>\n      <td>130</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.277778</td>\n      <td>0.250924</td>\n      <td>0.333333</td>\n      <td>0.365148</td>\n      <td>0.888889</td>\n      <td>0.000000</td>\n      <td>2.555556</td>\n      <td>0.111111</td>\n      <td>-2.666667</td>\n      <td>5.000000</td>\n      <td>-2.333333</td>\n      <td>2.555556</td>\n      <td>1.000000</td>\n      <td>-2.123254</td>\n      <td>foliage</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>202</td>\n      <td>41</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.944448</td>\n      <td>0.772202</td>\n      <td>1.111112</td>\n      <td>1.025597</td>\n      <td>123.037040</td>\n      <td>111.888885</td>\n      <td>139.777790</td>\n      <td>117.444440</td>\n      <td>-33.444443</td>\n      <td>50.222220</td>\n      <td>-16.777779</td>\n      <td>139.777790</td>\n      <td>0.199347</td>\n      <td>-2.299918</td>\n      <td>sky</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32</td>\n      <td>173</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.722222</td>\n      <td>1.781593</td>\n      <td>9.000000</td>\n      <td>6.749488</td>\n      <td>43.592594</td>\n      <td>39.555557</td>\n      <td>52.888890</td>\n      <td>38.333336</td>\n      <td>-12.111111</td>\n      <td>27.888890</td>\n      <td>-15.777778</td>\n      <td>52.888890</td>\n      <td>0.266914</td>\n      <td>-1.998857</td>\n      <td>path</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>61</td>\n      <td>197</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.444444</td>\n      <td>1.515353</td>\n      <td>2.611111</td>\n      <td>1.925463</td>\n      <td>49.592594</td>\n      <td>44.222220</td>\n      <td>61.555557</td>\n      <td>43.000000</td>\n      <td>-16.111110</td>\n      <td>35.888890</td>\n      <td>-19.777779</td>\n      <td>61.555557</td>\n      <td>0.302925</td>\n      <td>-2.022274</td>\n      <td>path</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2305</th>\n      <td>30</td>\n      <td>102</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.222222</td>\n      <td>0.118518</td>\n      <td>1.333333</td>\n      <td>0.800000</td>\n      <td>20.259260</td>\n      <td>20.333334</td>\n      <td>25.000000</td>\n      <td>15.444445</td>\n      <td>0.222222</td>\n      <td>14.222222</td>\n      <td>-14.444445</td>\n      <td>25.000000</td>\n      <td>0.381059</td>\n      <td>-1.555097</td>\n      <td>brickface</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2306</th>\n      <td>143</td>\n      <td>24</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.277777</td>\n      <td>0.907406</td>\n      <td>0.888888</td>\n      <td>1.140749</td>\n      <td>127.629630</td>\n      <td>117.666664</td>\n      <td>141.666670</td>\n      <td>123.555560</td>\n      <td>-29.888890</td>\n      <td>42.111110</td>\n      <td>-12.222222</td>\n      <td>141.666670</td>\n      <td>0.169397</td>\n      <td>-2.349252</td>\n      <td>sky</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2307</th>\n      <td>80</td>\n      <td>72</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.222223</td>\n      <td>1.003697</td>\n      <td>1.444444</td>\n      <td>1.167461</td>\n      <td>59.000000</td>\n      <td>51.333332</td>\n      <td>74.444440</td>\n      <td>51.222220</td>\n      <td>-23.000000</td>\n      <td>46.333332</td>\n      <td>-23.333334</td>\n      <td>74.444440</td>\n      <td>0.314606</td>\n      <td>-2.090221</td>\n      <td>cement</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2308</th>\n      <td>98</td>\n      <td>133</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.555555</td>\n      <td>0.172133</td>\n      <td>0.388889</td>\n      <td>0.327731</td>\n      <td>0.962963</td>\n      <td>0.000000</td>\n      <td>2.777778</td>\n      <td>0.111111</td>\n      <td>-2.888889</td>\n      <td>5.444445</td>\n      <td>-2.555556</td>\n      <td>2.777778</td>\n      <td>1.000000</td>\n      <td>-2.123254</td>\n      <td>foliage</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2309</th>\n      <td>19</td>\n      <td>147</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.222222</td>\n      <td>0.074074</td>\n      <td>0.500000</td>\n      <td>0.077778</td>\n      <td>4.148148</td>\n      <td>3.888889</td>\n      <td>6.666666</td>\n      <td>1.888889</td>\n      <td>-0.777778</td>\n      <td>7.555555</td>\n      <td>-6.777778</td>\n      <td>7.000000</td>\n      <td>0.713228</td>\n      <td>-1.475643</td>\n      <td>brickface</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2310 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_original = pd.read_csv(datasets.ImageSegments().path)\n",
    "dataset_original['categorical_label'] = LabelEncoder().fit_transform(dataset_original['category'])\n",
    "\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      region-centroid-col  region-centroid-row  short-line-density-5  \\\n1                     113                  130                   0.0   \n2                     202                   41                   0.0   \n6                     197                  229                   0.0   \n7                      29                  111                   0.0   \n8                       1                   81                   0.0   \n...                   ...                  ...                   ...   \n2305                   30                  102                   0.0   \n2306                  143                   24                   0.0   \n2307                   80                   72                   0.0   \n2308                   98                  133                   0.0   \n2309                   19                  147                   0.0   \n\n      short-line-density-2  vedge-mean    vegde-sd  hedge-mean    hedge-sd  \\\n1                      0.0    0.277778    0.250924    0.333333    0.365148   \n2                      0.0    0.944448    0.772202    1.111112    1.025597   \n6                      0.0    1.388888    1.574073    1.166666    0.566666   \n7                      0.0    0.388889    0.240741    0.611111    0.151852   \n8                      0.0   12.166667  267.455540    9.222222  205.362960   \n...                    ...         ...         ...         ...         ...   \n2305                   0.0    1.222222    0.118518    1.333333    0.800000   \n2306                   0.0    1.277777    0.907406    0.888888    1.140749   \n2307                   0.0    1.222223    1.003697    1.444444    1.167461   \n2308                   0.0    0.555555    0.172133    0.388889    0.327731   \n2309                   0.0    0.222222    0.074074    0.500000    0.077778   \n\n      intensity-mean  rawred-mean  rawblue-mean  rawgreen-mean  exred-mean  \\\n1           0.888889     0.000000      2.555556       0.111111   -2.666667   \n2         123.037040   111.888885    139.777790     117.444440  -33.444443   \n6          17.740740    14.111111     17.888890      21.222221  -10.888889   \n7           5.407407     6.888889      6.333334       3.000000    4.444445   \n8          21.333334    14.000000     30.555555      19.444445  -22.000000   \n...              ...          ...           ...            ...         ...   \n2305       20.259260    20.333334     25.000000      15.444445    0.222222   \n2306      127.629630   117.666664    141.666670     123.555560  -29.888890   \n2307       59.000000    51.333332     74.444440      51.222220  -23.000000   \n2308        0.962963     0.000000      2.777778       0.111111   -2.888889   \n2309        4.148148     3.888889      6.666666       1.888889   -0.777778   \n\n      exblue-mean  exgreen-mean  value-mean  saturation-mean  hue-mean  \n1        5.000000     -2.333333    2.555556         1.000000 -2.123254  \n2       50.222220    -16.777779  139.777790         0.199347 -2.299918  \n6        0.444444     10.444445   21.222221         0.335717  2.651605  \n7        2.777778     -7.222222    6.888889         0.564153 -0.897859  \n8       27.666666     -5.666666   30.555555         0.595282 -2.438409  \n...           ...           ...         ...              ...       ...  \n2305    14.222222    -14.444445   25.000000         0.381059 -1.555097  \n2306    42.111110    -12.222222  141.666670         0.169397 -2.349252  \n2307    46.333332    -23.333334   74.444440         0.314606 -2.090221  \n2308     5.444445     -2.555556    2.777778         1.000000 -2.123254  \n2309     7.555555     -6.777778    7.000000         0.713228 -1.475643  \n\n[1980 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region-centroid-col</th>\n      <th>region-centroid-row</th>\n      <th>short-line-density-5</th>\n      <th>short-line-density-2</th>\n      <th>vedge-mean</th>\n      <th>vegde-sd</th>\n      <th>hedge-mean</th>\n      <th>hedge-sd</th>\n      <th>intensity-mean</th>\n      <th>rawred-mean</th>\n      <th>rawblue-mean</th>\n      <th>rawgreen-mean</th>\n      <th>exred-mean</th>\n      <th>exblue-mean</th>\n      <th>exgreen-mean</th>\n      <th>value-mean</th>\n      <th>saturation-mean</th>\n      <th>hue-mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>113</td>\n      <td>130</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.277778</td>\n      <td>0.250924</td>\n      <td>0.333333</td>\n      <td>0.365148</td>\n      <td>0.888889</td>\n      <td>0.000000</td>\n      <td>2.555556</td>\n      <td>0.111111</td>\n      <td>-2.666667</td>\n      <td>5.000000</td>\n      <td>-2.333333</td>\n      <td>2.555556</td>\n      <td>1.000000</td>\n      <td>-2.123254</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>202</td>\n      <td>41</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.944448</td>\n      <td>0.772202</td>\n      <td>1.111112</td>\n      <td>1.025597</td>\n      <td>123.037040</td>\n      <td>111.888885</td>\n      <td>139.777790</td>\n      <td>117.444440</td>\n      <td>-33.444443</td>\n      <td>50.222220</td>\n      <td>-16.777779</td>\n      <td>139.777790</td>\n      <td>0.199347</td>\n      <td>-2.299918</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>197</td>\n      <td>229</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.388888</td>\n      <td>1.574073</td>\n      <td>1.166666</td>\n      <td>0.566666</td>\n      <td>17.740740</td>\n      <td>14.111111</td>\n      <td>17.888890</td>\n      <td>21.222221</td>\n      <td>-10.888889</td>\n      <td>0.444444</td>\n      <td>10.444445</td>\n      <td>21.222221</td>\n      <td>0.335717</td>\n      <td>2.651605</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>29</td>\n      <td>111</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.388889</td>\n      <td>0.240741</td>\n      <td>0.611111</td>\n      <td>0.151852</td>\n      <td>5.407407</td>\n      <td>6.888889</td>\n      <td>6.333334</td>\n      <td>3.000000</td>\n      <td>4.444445</td>\n      <td>2.777778</td>\n      <td>-7.222222</td>\n      <td>6.888889</td>\n      <td>0.564153</td>\n      <td>-0.897859</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>81</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.166667</td>\n      <td>267.455540</td>\n      <td>9.222222</td>\n      <td>205.362960</td>\n      <td>21.333334</td>\n      <td>14.000000</td>\n      <td>30.555555</td>\n      <td>19.444445</td>\n      <td>-22.000000</td>\n      <td>27.666666</td>\n      <td>-5.666666</td>\n      <td>30.555555</td>\n      <td>0.595282</td>\n      <td>-2.438409</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2305</th>\n      <td>30</td>\n      <td>102</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.222222</td>\n      <td>0.118518</td>\n      <td>1.333333</td>\n      <td>0.800000</td>\n      <td>20.259260</td>\n      <td>20.333334</td>\n      <td>25.000000</td>\n      <td>15.444445</td>\n      <td>0.222222</td>\n      <td>14.222222</td>\n      <td>-14.444445</td>\n      <td>25.000000</td>\n      <td>0.381059</td>\n      <td>-1.555097</td>\n    </tr>\n    <tr>\n      <th>2306</th>\n      <td>143</td>\n      <td>24</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.277777</td>\n      <td>0.907406</td>\n      <td>0.888888</td>\n      <td>1.140749</td>\n      <td>127.629630</td>\n      <td>117.666664</td>\n      <td>141.666670</td>\n      <td>123.555560</td>\n      <td>-29.888890</td>\n      <td>42.111110</td>\n      <td>-12.222222</td>\n      <td>141.666670</td>\n      <td>0.169397</td>\n      <td>-2.349252</td>\n    </tr>\n    <tr>\n      <th>2307</th>\n      <td>80</td>\n      <td>72</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.222223</td>\n      <td>1.003697</td>\n      <td>1.444444</td>\n      <td>1.167461</td>\n      <td>59.000000</td>\n      <td>51.333332</td>\n      <td>74.444440</td>\n      <td>51.222220</td>\n      <td>-23.000000</td>\n      <td>46.333332</td>\n      <td>-23.333334</td>\n      <td>74.444440</td>\n      <td>0.314606</td>\n      <td>-2.090221</td>\n    </tr>\n    <tr>\n      <th>2308</th>\n      <td>98</td>\n      <td>133</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.555555</td>\n      <td>0.172133</td>\n      <td>0.388889</td>\n      <td>0.327731</td>\n      <td>0.962963</td>\n      <td>0.000000</td>\n      <td>2.777778</td>\n      <td>0.111111</td>\n      <td>-2.888889</td>\n      <td>5.444445</td>\n      <td>-2.555556</td>\n      <td>2.777778</td>\n      <td>1.000000</td>\n      <td>-2.123254</td>\n    </tr>\n    <tr>\n      <th>2309</th>\n      <td>19</td>\n      <td>147</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.222222</td>\n      <td>0.074074</td>\n      <td>0.500000</td>\n      <td>0.077778</td>\n      <td>4.148148</td>\n      <td>3.888889</td>\n      <td>6.666666</td>\n      <td>1.888889</td>\n      <td>-0.777778</td>\n      <td>7.555555</td>\n      <td>-6.777778</td>\n      <td>7.000000</td>\n      <td>0.713228</td>\n      <td>-1.475643</td>\n    </tr>\n  </tbody>\n</table>\n<p>1980 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = dataset_original[dataset_original['category'] != 'path']\n",
    "category_path = dataset_original[dataset_original['category'] == 'path']\n",
    "\n",
    "Y_train_simbolic = df_train.pop('category')\n",
    "Y_train_numeric = df_train.pop('categorical_label')\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['brickface', 'cement', 'foliage', 'grass', 'sky', 'window'],\n      dtype=object)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train_simbolic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INICIO TREINOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=5001): Max retries exceeded with url: /classifier/init (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002A99CA21508>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001B[0m in \u001B[0;36m_new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    156\u001B[0m             conn = connection.create_connection(\n\u001B[1;32m--> 157\u001B[1;33m                 \u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dns_host\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mport\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mextra_kw\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    158\u001B[0m             )\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001B[0m in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     83\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0merr\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 84\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001B[0m in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     73\u001B[0m                 \u001B[0msock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msource_address\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 74\u001B[1;33m             \u001B[0msock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msa\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     75\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0msock\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mConnectionRefusedError\u001B[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mNewConnectionError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    671\u001B[0m                 \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 672\u001B[1;33m                 \u001B[0mchunked\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mchunked\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    673\u001B[0m             )\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    386\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 387\u001B[1;33m             \u001B[0mconn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mhttplib_request_kw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    388\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[0;32m   1251\u001B[0m         \u001B[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1252\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_send_request\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbody\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1253\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36m_send_request\u001B[1;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[0;32m   1297\u001B[0m             \u001B[0mbody\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_encode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbody\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'body'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1298\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mendheaders\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbody\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencode_chunked\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1299\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36mendheaders\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1246\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mCannotSendHeader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1247\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_send_output\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmessage_body\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencode_chunked\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1248\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36m_send_output\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1025\u001B[0m         \u001B[1;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_buffer\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1026\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1027\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    965\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_open\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 966\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    967\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001B[0m in \u001B[0;36mconnect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    183\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mconnect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 184\u001B[1;33m         \u001B[0mconn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_new_conn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    185\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_prepare_conn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001B[0m in \u001B[0;36m_new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    168\u001B[0m             raise NewConnectionError(\n\u001B[1;32m--> 169\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"Failed to establish a new connection: %s\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    170\u001B[0m             )\n",
      "\u001B[1;31mNewConnectionError\u001B[0m: <urllib3.connection.HTTPConnection object at 0x000002A99CA21508>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    448\u001B[0m                     \u001B[0mretries\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_retries\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 449\u001B[1;33m                     \u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    450\u001B[0m                 )\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    719\u001B[0m             retries = retries.increment(\n\u001B[1;32m--> 720\u001B[1;33m                 \u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merror\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_pool\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_stacktrace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexc_info\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    721\u001B[0m             )\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001B[0m in \u001B[0;36mincrement\u001B[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[0;32m    435\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mnew_retry\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_exhausted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 436\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mMaxRetryError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merror\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mResponseError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcause\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    437\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMaxRetryError\u001B[0m: HTTPConnectionPool(host='127.0.0.1', port=5001): Max retries exceeded with url: /classifier/init (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002A99CA21508>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-aeed1b577f81>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'/init'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'type_model'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-4-001a034a4fd1>\u001B[0m in \u001B[0;36msend\u001B[1;34m(endpoint, params_dict, url)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mendpoint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'http://127.0.0.1:5001/classifier'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mrequests\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mendpoint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mget\u001B[1;34m(url, params, **kwargs)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m     \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msetdefault\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'allow_redirects'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'get'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[1;31m# cases, and look like a memory leak in others.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0msessions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSession\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    531\u001B[0m         }\n\u001B[0;32m    532\u001B[0m         \u001B[0msend_kwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msettings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 533\u001B[1;33m         \u001B[0mresp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0msend_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    534\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    535\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    644\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    645\u001B[0m         \u001B[1;31m# Send the request\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 646\u001B[1;33m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0madapter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    647\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    648\u001B[0m         \u001B[1;31m# Total elapsed time of the request (approximately)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    514\u001B[0m                 \u001B[1;32mraise\u001B[0m \u001B[0mSSLError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 516\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    517\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    518\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mClosedPoolError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mConnectionError\u001B[0m: HTTPConnectionPool(host='127.0.0.1', port=5001): Max retries exceeded with url: /classifier/init (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002A99CA21508>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "send('/init', {'type_model': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionResetError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    671\u001B[0m                 \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 672\u001B[1;33m                 \u001B[0mchunked\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mchunked\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    673\u001B[0m             )\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    420\u001B[0m                     \u001B[1;31m# Otherwise it looks like a bug in the code.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 421\u001B[1;33m                     \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    422\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mSocketError\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001B[0m in \u001B[0;36mraise_from\u001B[1;34m(value, from_value)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    415\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 416\u001B[1;33m                     \u001B[0mhttplib_response\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetresponse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    417\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36mgetresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1343\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1344\u001B[1;33m                 \u001B[0mresponse\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbegin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1345\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36mbegin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    305\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 306\u001B[1;33m             \u001B[0mversion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstatus\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreason\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_read_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    307\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mstatus\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mCONTINUE\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36m_read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    266\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_read_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 267\u001B[1;33m         \u001B[0mline\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_MAXLINE\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"iso-8859-1\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    268\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0m_MAXLINE\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    588\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 589\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    590\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mConnectionResetError\u001B[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mProtocolError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    448\u001B[0m                     \u001B[0mretries\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_retries\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 449\u001B[1;33m                     \u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    450\u001B[0m                 )\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    719\u001B[0m             retries = retries.increment(\n\u001B[1;32m--> 720\u001B[1;33m                 \u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merror\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_pool\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_stacktrace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexc_info\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    721\u001B[0m             )\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001B[0m in \u001B[0;36mincrement\u001B[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[0;32m    399\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mread\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mFalse\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_is_method_retryable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 400\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreraise\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merror\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_stacktrace\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    401\u001B[0m             \u001B[1;32melif\u001B[0m \u001B[0mread\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001B[0m in \u001B[0;36mreraise\u001B[1;34m(tp, value, tb)\u001B[0m\n\u001B[0;32m    733\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 734\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    735\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    671\u001B[0m                 \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 672\u001B[1;33m                 \u001B[0mchunked\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mchunked\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    673\u001B[0m             )\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    420\u001B[0m                     \u001B[1;31m# Otherwise it looks like a bug in the code.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 421\u001B[1;33m                     \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    422\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mSocketError\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001B[0m in \u001B[0;36mraise_from\u001B[1;34m(value, from_value)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    415\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 416\u001B[1;33m                     \u001B[0mhttplib_response\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetresponse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    417\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36mgetresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1343\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1344\u001B[1;33m                 \u001B[0mresponse\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbegin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1345\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36mbegin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    305\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 306\u001B[1;33m             \u001B[0mversion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstatus\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreason\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_read_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    307\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mstatus\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mCONTINUE\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\http\\client.py\u001B[0m in \u001B[0;36m_read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    266\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_read_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 267\u001B[1;33m         \u001B[0mline\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_MAXLINE\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"iso-8859-1\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    268\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0m_MAXLINE\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    588\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 589\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    590\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mProtocolError\u001B[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-77f186e26987>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdf_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miterrows\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'/learn'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'x'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnumpy2dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'y'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mY_train_numeric\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-2-001a034a4fd1>\u001B[0m in \u001B[0;36msend\u001B[1;34m(endpoint, params_dict, url)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mendpoint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'http://127.0.0.1:5001/classifier'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mrequests\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mendpoint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mget\u001B[1;34m(url, params, **kwargs)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m     \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msetdefault\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'allow_redirects'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'get'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[1;31m# cases, and look like a memory leak in others.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0msessions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSession\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    531\u001B[0m         }\n\u001B[0;32m    532\u001B[0m         \u001B[0msend_kwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msettings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 533\u001B[1;33m         \u001B[0mresp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0msend_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    534\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    535\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    644\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    645\u001B[0m         \u001B[1;31m# Send the request\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 646\u001B[1;33m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0madapter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    647\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    648\u001B[0m         \u001B[1;31m# Total elapsed time of the request (approximately)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    496\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    497\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mProtocolError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msocket\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 498\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    499\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    500\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mMaxRetryError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mConnectionError\u001B[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "for k, x in df_train.iterrows():\n",
    "    send('/learn', {'x': numpy2dict(x.to_numpy()), 'y': int(Y_train_numeric.loc[k])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Supervisionada :0.9702020202020202\n"
     ]
    }
   ],
   "source": [
    "predict = []\n",
    "truth = []\n",
    "\n",
    "for idx, x in df_train.iterrows():\n",
    "    y_pred = send('/predict', {'type': 'one', 'x': numpy2dict(x.to_numpy())})['y_pred']\n",
    "    predict.append(y_pred)\n",
    "    y = Y_train_numeric.loc[idx]\n",
    "    truth.append(y)\n",
    "    #print('idx: ' + str(idx) + ' | y_pred: ' + str(y_pred) + ' | truth: ' + str(y))\n",
    "    \n",
    "print(\"Acurácia Supervisionada :\" + str(accuracy_score(truth, predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 1.055450475836157e-176,\n",
       " '1': 5.4605231917914635e-33,\n",
       " '2': 2.455533682308092e-77,\n",
       " '3': 0.0,\n",
       " '5': 1.0,\n",
       " '6': 2.8646836585346085e-155}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = send('/predict', {'type': 'proba', 'x': numpy2dict(df_train.iloc[1])})['y_pred']\n",
    "\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sky\n"
     ]
    }
   ],
   "source": [
    "idx = df_train.index[1]\n",
    "\n",
    "print(dataset_original.iloc[idx]['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10 : 0.00\n",
      "0.15 : 0.00\n",
      "0.20 : 0.00\n",
      "0.25 : 0.00\n",
      "0.30 : 0.00\n",
      "0.35 : 0.00\n",
      "0.40 : 0.00\n",
      "0.45 : 3.00\n",
      "0.50 : 5.00\n",
      "0.55 : 21.00\n",
      "0.60 : 36.00\n",
      "0.65 : 57.00\n",
      "0.70 : 69.00\n",
      "0.75 : 93.00\n",
      "0.80 : 118.00\n",
      "0.85 : 139.00\n",
      "0.90 : 170.00\n",
      "0.95 : 240.00\n"
     ]
    }
   ],
   "source": [
    "#QUERO SABER SE EXISTE ALGUMA LEITURA QUE TENHA A PROBA MAX < 0.5, OU  SEJA, INDECISAO\n",
    "\n",
    "thresholds = np.arange(0.1, 1, 0.05)\n",
    "\n",
    "for threshold in thresholds: \n",
    "    ind = 0\n",
    "    for idx, x in df_train.iterrows():\n",
    "        y_pred_proba = send('/predict', {'type': 'proba', 'x': numpy2dict(x.to_numpy())})['y_pred']\n",
    "\n",
    "        max_proba = max(y_pred_proba.items(), key = lambda k : k[1])\n",
    "\n",
    "        #indecisao\n",
    "        if (max_proba[1] < threshold):           \n",
    "            ind = ind+1\n",
    "    print('{:.2f} : {:.2f}'.format(threshold, ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10 : 0.00\n",
      "0.15 : 0.00\n",
      "0.20 : 0.00\n",
      "0.25 : 0.00\n",
      "0.30 : 0.00\n",
      "0.35 : 0.00\n",
      "0.40 : 0.00\n",
      "0.45 : 0.00\n",
      "0.50 : 0.00\n",
      "0.55 : 0.00\n",
      "0.60 : 0.00\n",
      "0.65 : 0.00\n",
      "0.70 : 1.00\n",
      "0.75 : 2.00\n",
      "0.80 : 5.00\n",
      "0.85 : 8.00\n",
      "0.90 : 14.00\n",
      "0.95 : 16.00\n"
     ]
    }
   ],
   "source": [
    "#VOU INSERIR A NOVA CLASSE\n",
    "\n",
    "#VERIFICAR SE ELA ESTÁ SENDO CLASSIFICADO COMO UMA CLASSE CONHECIDA\n",
    "#VERIFICAR SE ELA ESTÁ SENDO CLASSIFICADA COMO DESCONHECIDA (threshold < 0.3 de certeza na classe mais provavel)\n",
    "\n",
    "X_test = category_path.iloc[:, :-2]\n",
    "\n",
    "for threshold in thresholds: \n",
    "    ind = 0\n",
    "    for idx, x in X_test.iterrows():\n",
    "        y_pred_proba = send('/predict', {'type': 'proba', 'x': numpy2dict(x.to_numpy())})['y_pred']\n",
    "\n",
    "        max_proba = max(y_pred_proba.items(), key = lambda k : k[1])\n",
    "        if (max_proba[1] < threshold): #0.7 FOI O VALOR DE INDECISÃO QUE NAO CLASSIFICARIA INCORRETAMENTE AS NOVAS AMOSTRAS. ESSAS SERIAM ENVIADAS PARA OS EXPERTS\n",
    "            #print('idx train: ' + str(idx))\n",
    "            ind = ind+1\n",
    "\n",
    "    print('{:.2f} : {:.2f}'.format(threshold, ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METODOLOGIA\n",
    "\n",
    "## DEFINIR DATASETS\n",
    "\n",
    "S1 = {brickface, cement, foliage, grass, sky, window}\n",
    "\n",
    "S1_1 = 70% S1 (de cada classe)\n",
    "\n",
    "S1_2 = 30% S1 (de cada classe)\n",
    "\n",
    "S2 = {path}\n",
    "\n",
    "S2_1 = 30% S2\n",
    "\n",
    "S2_2 = 70% S2\n",
    "\n",
    "S3 = {S1_2 + S2_2)\n",
    "\n",
    "## APLICAR METODOLOGIA\n",
    "\n",
    "1. train S1_1\n",
    "\n",
    "2. predict S2_1\n",
    "\n",
    "3. cluster S2_1\n",
    "\n",
    "4. train S2_1\n",
    "\n",
    "5. validar S3 => métricas acurácia\n",
    "\n",
    "6. Anomaly Detection (detector phase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## preparando dados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from river import linear_model, metrics, multiclass, preprocessing\n",
    "from river import ensemble\n",
    "from river import neighbors\n",
    "from river import tree\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = dataset_original[dataset_original['category'] != 'path']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(S1.iloc[:,:-2], S1.iloc[:, -1], stratify=S1.iloc[:, -1], test_size=0.3)\n",
    "\n",
    "S1_1 = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "S1_2 = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "S2 = dataset_original[dataset_original['category'] == 'path']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(S2.iloc[:,:-2], S2.iloc[:, -1], test_size=0.7)\n",
    "\n",
    "S2_1 = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "S2_2 = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "S3 = pd.concat([S2_1, S2_2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. train(S1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "S1_1_x = S1_1.iloc[:, :-1]\n",
    "S1_1_y = S1_1.iloc[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Criando o classificador RIVER KNN ADWIN_CLASSIFIER\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "classifier = ensemble.BaggingClassifier(\n",
    "    model=(\n",
    "            preprocessing.StandardScaler() |\n",
    "            neighbors.KNNADWINClassifier()\n",
    "    )\n",
    ")\n",
    "\n",
    "for k, x in S1_1_x.iterrows():\n",
    "    classifier.predict_one(numpy2dict(x.to_numpy()))\n",
    "    classifier = classifier.learn_one(numpy2dict(x.to_numpy()), int(S1_1_y.loc[k]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Criando o classificador SCIKIT_MULTIFLOW KNN\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from skmultiflow.lazy import KNNClassifier\n",
    "\n",
    "classifier_knn_sk_mult = KNNClassifier(n_neighbors=8, max_window_size=2000, leaf_size=40)\n",
    "\n",
    "for k, x in S1_1_x.iterrows():\n",
    "    classifier_knn_sk_mult = classifier_knn_sk_mult.partial_fit(x.to_numpy().reshape(1, x.shape[0]), [int(S1_1_y.loc[k])])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. predict(S2_1)\n",
    "\n",
    "- nova categoria\n",
    "- selecionar com THRESHOLD 0.95\n",
    "- quantidade UNK -> K (erro)\n",
    "- quantidade UNK -> UNK (acerto)\n",
    "- enviar UNK -> UNK para Cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "99"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2_1_x = S2_1.iloc[:, :-1]\n",
    "S2_1_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as know 0.00% : as unknown 100.00%\n"
     ]
    }
   ],
   "source": [
    "## 70% dos dados da classe 4 (path) foram classificadas, e devem ser marcadas como unknown\n",
    "\n",
    "threshold = 0.95\n",
    "classified_as_known = 0\n",
    "DATASET_3 = []\n",
    "\n",
    "for idx, x in S2_1_x.iterrows():\n",
    "    y_pred_proba = classifier.predict_proba_one(numpy2dict(x.to_numpy()))\n",
    "\n",
    "    max_proba = max(y_pred_proba.items(), key = lambda k : k[1])\n",
    "    if (max_proba[1] < threshold): #indecisao\n",
    "        DATASET_3.append(idx)\n",
    "    else: #certeza\n",
    "        classified_as_known = classified_as_known + 1\n",
    "\n",
    "\n",
    "print('as know {:.2f}% : as unknown {:.2f}%'.format(classified_as_known/S2_1_x.shape[0]*100, len(DATASET_3)/S2_1_x.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      region-centroid-col  region-centroid-row  short-line-density-5  \\\n1424                  149                  182              0.111111   \n777                   179                  162              0.000000   \n454                   165                  186              0.000000   \n942                    87                  196              0.111111   \n1439                   38                  200              0.000000   \n...                   ...                  ...                   ...   \n718                   239                  160              0.000000   \n1362                  254                  159              0.000000   \n1579                   37                  189              0.000000   \n767                   214                  161              0.000000   \n2085                  123                  194              0.000000   \n\n      short-line-density-2  vedge-mean  vegde-sd  hedge-mean    hedge-sd  \\\n1424                   0.0    3.111113  3.208783    7.000000    5.648992   \n777                    0.0    1.944445  1.307408   14.055556    5.929622   \n454                    0.0    2.555555  1.572919    2.000000    1.173788   \n942                    0.0    1.333332  0.869228    2.222222    1.668887   \n1439                   0.0    3.444445  2.125681    3.444445    1.204929   \n...                    ...         ...       ...         ...         ...   \n718                    0.0    1.833333  0.922221    5.944443    4.596297   \n1362                   0.0    3.555555  7.540740   14.833333  152.700000   \n1579                   0.0    1.388889  1.485184    5.722223   23.885176   \n767                    0.0    3.722222  0.729634   11.500000   18.922234   \n2085                   0.0    2.555556  1.784708    9.111109    7.713385   \n\n      intensity-mean  rawred-mean  rawblue-mean  rawgreen-mean  exred-mean  \\\n1424       39.851852    37.222220     47.333332      35.000000   -7.888889   \n777        40.296295    34.666668     49.222220      37.000000  -16.888890   \n454        49.518520    45.111110     61.111110      42.333336  -13.222222   \n942        61.592594    55.000000     75.666670      54.111110  -19.777779   \n1439       55.962963    49.000000     70.222220      48.666668  -20.888890   \n...              ...          ...           ...            ...         ...   \n718        45.148148    37.888890     58.333332      39.222220  -21.777779   \n1362       36.629630    31.333334     46.222220      32.333336  -15.888889   \n1579       30.000000    27.111110     36.333336      26.555555   -8.666667   \n767        40.444443    35.333336     49.666668      36.333336  -15.333333   \n2085       60.814816    54.333332     74.888885      53.222220  -19.444445   \n\n      exblue-mean  exgreen-mean  value-mean  saturation-mean  hue-mean  \n1424    22.444445    -14.555555   47.333332         0.247790 -1.868277  \n777     26.777779     -9.888889   49.222220         0.289652 -2.341198  \n454     34.777780    -21.555555   61.111110         0.307257 -1.940813  \n942     42.222220    -22.444445   75.666670         0.287526 -2.048736  \n1439    42.777780    -21.888890   70.222220         0.309826 -2.080206  \n...           ...           ...         ...              ...       ...  \n718     39.555557    -17.777779   58.333332         0.352126 -2.162999  \n1362    28.777779    -12.888889   46.222220         0.294845 -2.316872  \n1579    19.000000    -10.333333   36.333336         0.265248 -2.050282  \n767     27.666666    -12.333333   49.666668         0.298056 -2.198939  \n2085    42.222220    -22.777779   74.888885         0.292382 -2.033605  \n\n[99 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region-centroid-col</th>\n      <th>region-centroid-row</th>\n      <th>short-line-density-5</th>\n      <th>short-line-density-2</th>\n      <th>vedge-mean</th>\n      <th>vegde-sd</th>\n      <th>hedge-mean</th>\n      <th>hedge-sd</th>\n      <th>intensity-mean</th>\n      <th>rawred-mean</th>\n      <th>rawblue-mean</th>\n      <th>rawgreen-mean</th>\n      <th>exred-mean</th>\n      <th>exblue-mean</th>\n      <th>exgreen-mean</th>\n      <th>value-mean</th>\n      <th>saturation-mean</th>\n      <th>hue-mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1424</th>\n      <td>149</td>\n      <td>182</td>\n      <td>0.111111</td>\n      <td>0.0</td>\n      <td>3.111113</td>\n      <td>3.208783</td>\n      <td>7.000000</td>\n      <td>5.648992</td>\n      <td>39.851852</td>\n      <td>37.222220</td>\n      <td>47.333332</td>\n      <td>35.000000</td>\n      <td>-7.888889</td>\n      <td>22.444445</td>\n      <td>-14.555555</td>\n      <td>47.333332</td>\n      <td>0.247790</td>\n      <td>-1.868277</td>\n    </tr>\n    <tr>\n      <th>777</th>\n      <td>179</td>\n      <td>162</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.944445</td>\n      <td>1.307408</td>\n      <td>14.055556</td>\n      <td>5.929622</td>\n      <td>40.296295</td>\n      <td>34.666668</td>\n      <td>49.222220</td>\n      <td>37.000000</td>\n      <td>-16.888890</td>\n      <td>26.777779</td>\n      <td>-9.888889</td>\n      <td>49.222220</td>\n      <td>0.289652</td>\n      <td>-2.341198</td>\n    </tr>\n    <tr>\n      <th>454</th>\n      <td>165</td>\n      <td>186</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2.555555</td>\n      <td>1.572919</td>\n      <td>2.000000</td>\n      <td>1.173788</td>\n      <td>49.518520</td>\n      <td>45.111110</td>\n      <td>61.111110</td>\n      <td>42.333336</td>\n      <td>-13.222222</td>\n      <td>34.777780</td>\n      <td>-21.555555</td>\n      <td>61.111110</td>\n      <td>0.307257</td>\n      <td>-1.940813</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>87</td>\n      <td>196</td>\n      <td>0.111111</td>\n      <td>0.0</td>\n      <td>1.333332</td>\n      <td>0.869228</td>\n      <td>2.222222</td>\n      <td>1.668887</td>\n      <td>61.592594</td>\n      <td>55.000000</td>\n      <td>75.666670</td>\n      <td>54.111110</td>\n      <td>-19.777779</td>\n      <td>42.222220</td>\n      <td>-22.444445</td>\n      <td>75.666670</td>\n      <td>0.287526</td>\n      <td>-2.048736</td>\n    </tr>\n    <tr>\n      <th>1439</th>\n      <td>38</td>\n      <td>200</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3.444445</td>\n      <td>2.125681</td>\n      <td>3.444445</td>\n      <td>1.204929</td>\n      <td>55.962963</td>\n      <td>49.000000</td>\n      <td>70.222220</td>\n      <td>48.666668</td>\n      <td>-20.888890</td>\n      <td>42.777780</td>\n      <td>-21.888890</td>\n      <td>70.222220</td>\n      <td>0.309826</td>\n      <td>-2.080206</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>718</th>\n      <td>239</td>\n      <td>160</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.833333</td>\n      <td>0.922221</td>\n      <td>5.944443</td>\n      <td>4.596297</td>\n      <td>45.148148</td>\n      <td>37.888890</td>\n      <td>58.333332</td>\n      <td>39.222220</td>\n      <td>-21.777779</td>\n      <td>39.555557</td>\n      <td>-17.777779</td>\n      <td>58.333332</td>\n      <td>0.352126</td>\n      <td>-2.162999</td>\n    </tr>\n    <tr>\n      <th>1362</th>\n      <td>254</td>\n      <td>159</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3.555555</td>\n      <td>7.540740</td>\n      <td>14.833333</td>\n      <td>152.700000</td>\n      <td>36.629630</td>\n      <td>31.333334</td>\n      <td>46.222220</td>\n      <td>32.333336</td>\n      <td>-15.888889</td>\n      <td>28.777779</td>\n      <td>-12.888889</td>\n      <td>46.222220</td>\n      <td>0.294845</td>\n      <td>-2.316872</td>\n    </tr>\n    <tr>\n      <th>1579</th>\n      <td>37</td>\n      <td>189</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.388889</td>\n      <td>1.485184</td>\n      <td>5.722223</td>\n      <td>23.885176</td>\n      <td>30.000000</td>\n      <td>27.111110</td>\n      <td>36.333336</td>\n      <td>26.555555</td>\n      <td>-8.666667</td>\n      <td>19.000000</td>\n      <td>-10.333333</td>\n      <td>36.333336</td>\n      <td>0.265248</td>\n      <td>-2.050282</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>214</td>\n      <td>161</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3.722222</td>\n      <td>0.729634</td>\n      <td>11.500000</td>\n      <td>18.922234</td>\n      <td>40.444443</td>\n      <td>35.333336</td>\n      <td>49.666668</td>\n      <td>36.333336</td>\n      <td>-15.333333</td>\n      <td>27.666666</td>\n      <td>-12.333333</td>\n      <td>49.666668</td>\n      <td>0.298056</td>\n      <td>-2.198939</td>\n    </tr>\n    <tr>\n      <th>2085</th>\n      <td>123</td>\n      <td>194</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2.555556</td>\n      <td>1.784708</td>\n      <td>9.111109</td>\n      <td>7.713385</td>\n      <td>60.814816</td>\n      <td>54.333332</td>\n      <td>74.888885</td>\n      <td>53.222220</td>\n      <td>-19.444445</td>\n      <td>42.222220</td>\n      <td>-22.777779</td>\n      <td>74.888885</td>\n      <td>0.292382</td>\n      <td>-2.033605</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2_1_DATASET_3 = S2_1_x.loc[DATASET_3, :]\n",
    "\n",
    "S2_1_DATASET_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. cluster(S2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cluster classe 4 (path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# precisa ser INCREMENTAL PCA\n",
    "# precisa ser INCREMENTAL StandardScaler\n",
    "\n",
    "pca = PCA(.95)\n",
    "\n",
    "S2_1_cluster_pca = pd.DataFrame(pca.fit_transform(S2_1_DATASET_3).tolist())\n",
    "\n",
    "S2_1_cluster_pca_ss = StandardScaler().fit_transform(S2_1_cluster_pca.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Incremental DBSTREAM"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from river import cluster\n",
    "\n",
    "y_pred_dbstream = []\n",
    "dbstream = cluster.DBSTREAM(clustering_threshold = 2)\n",
    "\n",
    "for x in S2_1_cluster_pca_ss:\n",
    "    dbstream.learn_one(numpy2dict(x))\n",
    "    y_pred_dbstream.append(dbstream.predict_one(numpy2dict(x)))\n",
    "\n",
    "res =  [(el, y_pred_dbstream.count(el)) for el in y_pred_dbstream]\n",
    "y_pred_dbstream_grouped = list(OrderedDict(res).items())\n",
    "print(dbstream.n_clusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### DenStream"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "denstream = cluster.DenStream()\n",
    "\n",
    "y_pred_denstream = []\n",
    "for x in S2_1_cluster_pca_ss:\n",
    "    denstream.learn_one(numpy2dict(x))\n",
    "\n",
    "for x in S2_1_cluster_pca_ss:\n",
    "    y_pred_denstream.append(denstream.predict_one(numpy2dict(x)))\n",
    "\n",
    "print(denstream.n_clusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### DBSCAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd Labels DBSCAN offline: 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(metric='manhattan').fit(S2_1_cluster_pca_ss)\n",
    "\n",
    "dbscan_labels_list = dbscan.labels_.reshape(1, dbscan.labels_.shape[0]).tolist()[0]\n",
    "\n",
    "res =  [(el, dbscan_labels_list.count(el)) for el in dbscan_labels_list]\n",
    "y_pred_dbscan_grouped = list(OrderedDict(res).items())\n",
    "\n",
    "print('Qtd Labels DBSCAN offline: ' + str(len(np.unique(dbscan.labels_))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### TEDA Cloud"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "#### CLOUD ####\n",
    "class Cloud:\n",
    "\n",
    "    def __init__(self, sample=[], name='Default Class'):\n",
    "        self.name = name\n",
    "        self.var = 0\n",
    "        self.n = 0\n",
    "        self.covmat = []\n",
    "\n",
    "        if (len(sample) > 0):\n",
    "            self.mean = sample\n",
    "            self.n = 1\n",
    "            self.covmat = np.zeros((sample.shape[0], sample.shape[0]))\n",
    "\n",
    "    def updateCloud(self, mu=[], var=0, n=0, covmat=[]):\n",
    "        self.mean = mu\n",
    "        self.var = var\n",
    "        self.n = n\n",
    "        self.covmat = covmat\n",
    "\n",
    "    def addPoint(self, sample=[]):\n",
    "        if (self.n == 0):\n",
    "            self.n = 1\n",
    "            self.mean = sample\n",
    "            self.var = 0\n",
    "            self.covmat = np.zeros((self.mean.shape[0], self.mean.shape[0]))\n",
    "        else:\n",
    "            self.n = self.n + 1\n",
    "            self.mean = self.calculate_mean(sample, self.n)\n",
    "            self.var = self.calculate_variance(sample, self.n, self.mean)\n",
    "            self.covmat = self.calculate_variance_matrix(sample, self.n, self.mean)\n",
    "\n",
    "\n",
    "    def calculateZeta(self, sample=[], similarity_measure='euclidean'):\n",
    "        if self.n == 0:\n",
    "            zeta = math.inf\n",
    "            return zeta\n",
    "\n",
    "        n_ = self.n + 1\n",
    "        mean_ = self.calculate_mean(sample, n_)\n",
    "        var_ = self.calculate_variance(sample, n_, mean_)\n",
    "        covmat_ = self.calculate_variance_matrix(sample, n_, mean_)\n",
    "\n",
    "\n",
    "        if (similarity_measure.lower() == 'euclidean'):\n",
    "            ksi = np.maximum(self.calculate_eccentricity(sample, self.n, mean_, var_), 0.0001)\n",
    "        else:\n",
    "            ksi = np.maximum(self.calculate_eccentricity(sample, n_, mean_, var_, covmat_, 'mahalanobis'), 0.0001)\n",
    "\n",
    "        zeta = ksi / 2\n",
    "        return zeta\n",
    "\n",
    "    def calculate_mean(self, sample, n):\n",
    "        return ((n - 1) / n) * self.mean + (1 / n) * sample\n",
    "\n",
    "    def calculate_variance(self, sample, n, mean):\n",
    "        return ((n - 1) / n) * self.var + (1 / (n)) * LA.norm(sample - mean) ** 2\n",
    "\n",
    "    def calculate_variance_matrix(self, sample, n, mean):\n",
    "        a = (n - 1) / n\n",
    "        b = a * self.covmat\n",
    "        c = [sample - mean]\n",
    "        d = np.transpose(c)\n",
    "        e = (1 / n) * d    ##TALVEZ SEJA 1 / (n-1)\n",
    "\n",
    "        f = b + e * c\n",
    "\n",
    "        return f\n",
    "\n",
    "    def calculate_eccentricity(self, sample, n, mean, variance, covmat = [], similarity_measure = 'euclidean'):\n",
    "\n",
    "        a = 1 / n\n",
    "\n",
    "        if (similarity_measure == 'euclidean'):\n",
    "            b = [mean - sample]\n",
    "            c = np.transpose(b)\n",
    "            d = n * variance\n",
    "            e = np.dot(b, c)\n",
    "            f = e / d\n",
    "\n",
    "            r = distance.euclidean(sample, mean)\n",
    "\n",
    "            ksi = a + f\n",
    "        else: # mahalanobis_formula => (sample - mean).T * covmat*-1 * (sample - mean)\n",
    "\n",
    "            d_mahalanobis = np.zeros((1,1), dtype=float) + distance.mahalanobis(mean, sample, LA.pinv(covmat))**2\n",
    "\n",
    "            h = n * len(mean) #nao entendi para que isso - parece a ponderacao do n elementos pela qtd de dimensoes\n",
    "            m = d_mahalanobis / h\n",
    "\n",
    "            ksi = a + m\n",
    "\n",
    "        return ksi\n",
    "\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "################################ AUTOCLOUD ################################\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "class AutoCloud:\n",
    "\n",
    "    def __init__(self, m = 2, similarity_measure = 'euclidean', auto_merge = True, display = False):\n",
    "        self.k = 0\n",
    "        self.cloudList = []\n",
    "        self.predictions = {}\n",
    "        self.predictions_by_sample = {}\n",
    "        self.initialize_intersection_list()\n",
    "        self.initialize_intersection_matrix()\n",
    "        self.contMerge = 0\n",
    "        self.dimension = 0\n",
    "        self.similarityMeasure = similarity_measure\n",
    "        self.autoMerge = auto_merge\n",
    "        self.m = m\n",
    "        self.display = display\n",
    "\n",
    "    def run(self, sample = [], label = None):\n",
    "\n",
    "        if (self.dimension == 0):\n",
    "            self.dimension = sample.shape[0]\n",
    "        else:\n",
    "            if (self.dimension != sample.shape[0]):\n",
    "                raise Exception('The dimension of the current data sample is different from the points read so far.')\n",
    "\n",
    "        if (label != None): #para supervisionado - aqui temos também o Y (label) da amostra\n",
    "\n",
    "            while (len(self.cloudList) < label): #cria a qtd de classes\n",
    "                self.create_cloud(sample)\n",
    "\n",
    "            self.cloudList[label - 1].addPoint(sample)\n",
    "            self.k = self.k + 1\n",
    "\n",
    "            self.initialize_intersection_list()\n",
    "            self.membershipList = [0] * len(self.cloudList)\n",
    "            self.membershipList[label - 1] = 1\n",
    "            self.intersectionList[label - 1] = 1\n",
    "            self.initialize_intersection_matrix()\n",
    "\n",
    "            return label, self.membershipList\n",
    "\n",
    "        else:\n",
    "            self.k = self.k + 1\n",
    "            self.initialize_intersection_list()\n",
    "\n",
    "            if (self.k == 1):\n",
    "                self.cloudList.append(Cloud(sample = sample, name = 'Class 1'))\n",
    "                self.initialize_intersection_list()\n",
    "                self.initialize_intersection_matrix()\n",
    "                self.membershipList = [1]\n",
    "            elif (self.k == 2):\n",
    "                self.cloudList[0].addPoint(sample)\n",
    "                self.membershipList = [1]\n",
    "            elif (self.k >= 3):\n",
    "                createCloud = True\n",
    "                tauList = np.zeros((len(self.cloudList), 1))\n",
    "\n",
    "                for i_cloud, cloud in enumerate(self.cloudList):\n",
    "                    zeta = cloud.calculateZeta(sample, self.similarityMeasure) #??eccentricity | ?? norm_eccentricity\n",
    "                    tau = 1 - zeta #??typicality\n",
    "                    tauList[i_cloud] = tau\n",
    "\n",
    "                    if (self.calculate_sample_belongs_to_cloud(zeta, cloud.n)):\n",
    "                        cloud.addPoint(sample)\n",
    "                        self.intersectionList[i_cloud] = 1\n",
    "                        createCloud = False\n",
    "                    else:\n",
    "                        self.intersectionList[i_cloud] = 0\n",
    "\n",
    "                self.membershipList = tauList / sum(tauList)\n",
    "\n",
    "                ### NEW CLOUD ###\n",
    "                if (createCloud == True):\n",
    "                    self.create_cloud(sample)\n",
    "\n",
    "        amax = np.amax(self.membershipList)\n",
    "        where = np.where(self.membershipList == amax)\n",
    "        y_label = where[0][0]+1\n",
    "\n",
    "        if (self.autoMerge):\n",
    "            self.mergeClouds()\n",
    "\n",
    "        return y_label, self.membershipList\n",
    "\n",
    "    def mergeClouds(self):\n",
    "        i = 0\n",
    "\n",
    "        i_end = len(self.cloudList) - 1\n",
    "        while (i < i_end):\n",
    "\n",
    "            merge = False\n",
    "\n",
    "            j_end = np.arange(i + 1, len(self.cloudList)).reshape(-1)\n",
    "            for j in j_end:\n",
    "                if (self.intersectionList[i] == 1 and self.intersectionList[j] == 1):\n",
    "                    self.intersectionMatrix[i,j] = self.intersectionMatrix[i,j] + 1\n",
    "\n",
    "                ### recover information about clouds to be merged ###\n",
    "                n_i = self.cloudList[i].n\n",
    "                n_j = self.cloudList[j].n\n",
    "                mean_i = self.cloudList[i].mean\n",
    "                mean_j = self.cloudList[j].mean\n",
    "                var_i = self.cloudList[i].var\n",
    "                var_j = self.cloudList[j].var\n",
    "                covmat_i = self.cloudList[i].covmat\n",
    "                covmat_j = self.cloudList[j].covmat\n",
    "                nint = self.intersectionMatrix[i,j]\n",
    "\n",
    "                if (nint > (n_i - nint) or nint > (n_j - nint)):\n",
    "                    ### merge\n",
    "                    if (self.display):\n",
    "                        print('Merging clouds ' + str(i+1) + ' and ' + str(j+1) + ' at instant ' + str(self.k))\n",
    "                    ### calculate state of new cloud\n",
    "                    n = n_i + n_j - nint\n",
    "                    mean = ((n_i * mean_i) + (n_j * mean_j)) / (n_i + n_j)\n",
    "                    var = ((n_i - 1) * var_i + (n_j - 1) * var_j) / (n_i + n_j - 2)\n",
    "                    covmat = ((n_i - 1) * covmat_i + (n_j - 1) * covmat_j) / (n_i + n_j - 2)\n",
    "                    ### create new cloud cloud ###\n",
    "                    newCloud = Cloud()\n",
    "                    newCloud.updateCloud(mean, var, n, covmat)\n",
    "                    newCloud.name = 'Class ' + str(i+1) + '/' + str(j+1)\n",
    "\n",
    "                    ### update intersection list ###\n",
    "                    v_il1 = self.intersectionList[0: i]\n",
    "                    v_il2 = np.array([1])\n",
    "                    v_il3 = self.intersectionList[i + 1: j]\n",
    "                    v_il4 = self.intersectionList[j + 1: np.size(self.intersectionList)]\n",
    "                    self.intersectionList = np.concatenate((v_il1, v_il2, v_il3, v_il4), axis=None)\n",
    "\n",
    "                    ## update cloud list ###\n",
    "                    if (self.display):\n",
    "                        print(\"Cloud (label) : \" + str(i))\n",
    "                    v_c1 = self.cloudList[0: i]\n",
    "                    v_c2 = np.array([newCloud])\n",
    "                    v_c3 = self.cloudList[i + 1: j]\n",
    "                    v_c4 = self.cloudList[j + 1: np.size(self.cloudList)]\n",
    "                    self.cloudList = np.concatenate((v_c1, v_c2, v_c3, v_c4), axis=None)\n",
    "\n",
    "                    ### update intersection matrix ###\n",
    "                    A = self.intersectionMatrix\n",
    "\n",
    "                    #remover linha\n",
    "                    vb1_0 = A[0: i, :]\n",
    "                    vb2 = np.zeros((1, len(A)))\n",
    "                    vb3 = A[i + 1: j, :]\n",
    "                    vb4 = A[j + 1: len(A), :]\n",
    "                    B = np.concatenate(([vb1_0, vb2, vb3, vb4]))\n",
    "\n",
    "                    #remover coluna\n",
    "                    vb1_1 = B[:, 0: i]\n",
    "                    vb2 = np.zeros((len(B), 1))\n",
    "                    vb3 = B[:, i + 1: j]\n",
    "                    vb4 = B[:, j + 1: len(A)] ### acho que deveria ser LEN de B\n",
    "                    B = np.concatenate(([vb1_1, vb2, vb3, vb4]), axis=1)\n",
    "\n",
    "                    # calc nova coluna\n",
    "                    col = (A[:, i] + A[:, j]) * (A[:, i] * A[:, j] != 0)\n",
    "                    C = np.concatenate((col[0: j], col[j + 1: np.size(col)]))\n",
    "\n",
    "                    # calc nova linha\n",
    "                    lin = (A[i, :] + A[j, :]) * (A[i, :] * A[j, :] != 0)\n",
    "                    L = np.concatenate((lin[0: j], lin[j + 1: np.size(lin)]))\n",
    "\n",
    "                    #atualizar coluna\n",
    "                    B[:,i] = C\n",
    "\n",
    "                    #atualizar linha\n",
    "                    B[i,:] = L\n",
    "\n",
    "                    vb1_2 = A[[i], i+1 : j]\n",
    "                    vb2 = A[i+1 : j, [j]]\n",
    "                    vb3 = np.transpose(vb2)\n",
    "\n",
    "                    B[[i], i+1 : j] = vb1_2 + vb3\n",
    "\n",
    "                    self.intersectionMatrix = B\n",
    "\n",
    "                    merge = True\n",
    "                    self.contMerge = self.contMerge + 1\n",
    "                    break\n",
    "\n",
    "            if (merge == True):\n",
    "                i = 1\n",
    "            else:\n",
    "                i = i + 1\n",
    "\n",
    "\n",
    "    def initialize_intersection_matrix(self):\n",
    "        if (len(self.cloudList) == 0):\n",
    "            self.intersectionMatrix = np.zeros((1, 1))\n",
    "        else:\n",
    "            self.intersectionMatrix = np.zeros((len(self.cloudList), len(self.cloudList)))\n",
    "\n",
    "    def initialize_intersection_list(self):\n",
    "        if (len(self.cloudList) == 0):\n",
    "            self.intersectionList = []\n",
    "        else:\n",
    "            self.intersectionList = [0] * len(self.cloudList)\n",
    "\n",
    "\n",
    "    def calculateThreshold(self, s=None):\n",
    "        if (self.similarityMeasure.lower() == 'euclidean'):\n",
    "            th = (self.m ** 2 + 1) / (2 * (s))\n",
    "        else:\n",
    "            if (self.similarityMeasure.lower() == 'mahalanobis'):\n",
    "                th = (self.m ** 2 + self.dimension) / (2 * (s) * self.dimension)\n",
    "\n",
    "        threshold = th\n",
    "        return threshold\n",
    "\n",
    "    def create_cloud(self, sample):\n",
    "        cloud_number = len(self.cloudList) + 1\n",
    "        if (self.display):\n",
    "            print('Creating cloud ' + str(cloud_number) + ' at instant ' + str(self.k))\n",
    "\n",
    "        self.cloudList = np.append(self.cloudList, [Cloud(sample, 'Class ' + str(cloud_number))], axis=0)\n",
    "        self.intersectionList.append(1)\n",
    "        self.expand_intersection_matrix_with_zeros()\n",
    "\n",
    "    def calculate_sample_belongs_to_cloud(self, zeta, cloud_n):\n",
    "        return (zeta < math.inf and zeta <= self.calculateThreshold(cloud_n))\n",
    "\n",
    "    def expand_intersection_matrix_with_zeros(self):\n",
    "        self.intersectionMatrix = np.pad(self.intersectionMatrix, ((0, 1), (0, 1)), mode='constant', constant_values=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "clusterer = AutoCloud(2, 'mahalanobis')\n",
    "\n",
    "output = [0] * (S2_1_cluster_pca_ss.shape[0])\n",
    "\n",
    "for k, sample in pd.DataFrame(S2_1_cluster_pca_ss).iterrows():\n",
    "    y, _ = clusterer.run(sample)\n",
    "    output.append(y)\n",
    "\n",
    "print(len(np.unique(output)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cluster class 1 , 4 (foliage, path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "pca = PCA(.95)\n",
    "\n",
    "S2_1_4_cluster_pca = pd.DataFrame(pca.fit_transform(pd.concat([S2_1_DATASET_3,S1_1[S1_1['categorical_label'] == 1].iloc[0:94, :-1]])).tolist())\n",
    "\n",
    "S2_1_4_cluster_pca_ss = StandardScaler().fit_transform(S2_1_4_cluster_pca.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from river import cluster\n",
    "\n",
    "y_pred_dbstream = []\n",
    "dbstream_1_4 = cluster.DBSTREAM(clustering_threshold = 2)\n",
    "\n",
    "for x in S2_1_4_cluster_pca_ss:\n",
    "    dbstream_1_4.learn_one(numpy2dict(x))\n",
    "    y_pred_dbstream.append(dbstream_1_4.predict_one(numpy2dict(x)))\n",
    "\n",
    "print(dbstream_1_4.n_clusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "denstream_1_4 = cluster.DenStream()\n",
    "\n",
    "y_pred_denstream = []\n",
    "for x in S2_1_4_cluster_pca_ss:\n",
    "    denstream_1_4.learn_one(numpy2dict(x))\n",
    "\n",
    "for x in S2_1_4_cluster_pca_ss:\n",
    "    y_pred_denstream.append(denstream_1_4.predict_one(numpy2dict(x)))\n",
    "\n",
    "print(denstream_1_4.n_clusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd Labels DBSCAN offline: 4\n",
      "[-1  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0\n",
      "  0  0  0 -1  0 -1  0  0  0  0  0  0 -1 -1 -1  0 -1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 -1  0  0 -1  0  0  0 -1  0  0 -1  0  0  0  0 -1 -1  0\n",
      " -1  0 -1  0  0 -1  0  0 -1  0  0  0  0 -1  0  0  0 -1  0  0  0 -1  0 -1\n",
      "  0  0  2 -1  2  1 -1  1  1  1  1 -1  2 -1  1 -1 -1 -1 -1 -1 -1  1 -1  1\n",
      "  1  1 -1  2 -1  1 -1  2 -1 -1  1  2 -1 -1 -1 -1  1 -1  1  1  1 -1 -1 -1\n",
      " -1  1  2  2 -1  2  1 -1  1 -1  1  2  1  2  2 -1 -1  1 -1 -1  1 -1  1  1\n",
      "  1  2 -1  1 -1  1  1 -1  1  1 -1  1  1  1  1  2 -1  1  2 -1  1  2  2  2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan_1_4 = DBSCAN(metric='chebyshev').fit(S2_1_4_cluster_pca_ss)\n",
    "\n",
    "print('Qtd Labels DBSCAN offline: ' + str(len(np.unique(dbscan_1_4.labels_))))\n",
    "print(dbscan_1_4.labels_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### TEDA Cloud"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "autocloud_1_4 = AutoCloud(2, 'mahalanobis')\n",
    "\n",
    "output = [0] * (S2_1_4_cluster_pca_ss.shape[0])\n",
    "\n",
    "for k, sample in pd.DataFrame(S2_1_4_cluster_pca_ss).iterrows():\n",
    "    y, _ = autocloud_1_4.run(sample)\n",
    "    output.append(y)\n",
    "\n",
    "print(len(np.unique(output)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. train_classifier(S2_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### clusterer DBSTREAM -> CLASSIFIER"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "## COPIEI O CONTEUDO DO ENDPOINT KNOWN E VOU FAZER NA MÃO\n",
    "## POIS NAO TERIA COMO REVERTER O PCA, POIS NÃO TENHO A\n",
    "## REFERENCIA NO ARQUIVO _INIT_.PY\n",
    "\n",
    "slice_factor = 0.2\n",
    "\n",
    "# parameters\n",
    "cluster = 3\n",
    "_class = 35\n",
    "\n",
    "# obter centro cluster 0\n",
    "# obter samples do cluster 0\n",
    "# calcular os __slice_factor__ mais proximos\n",
    "# identificar que sao os samples no vetor original pré PCA e SS (posso utilizar o DB como apoio)\n",
    "# enviar os samples para o CLASSIFICADOR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obter centro do cluster X\n",
    "cluster_center = dbstream.centers[cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from river.utils import dict2numpy\n",
    "import math\n",
    "\n",
    "# pegar as keys dos samples para o cluster selecionado\n",
    "cluster_key_samples = [key for key, value in enumerate(y_pred_dbstream) if value == cluster]\n",
    "\n",
    "# pegar os samples para o cluster selecionado\n",
    "cluster_samples = S2_1_cluster_pca_ss[cluster_key_samples]\n",
    "\n",
    "# calcular distancias para cada sample\n",
    "distances = []\n",
    "for sample in cluster_samples:\n",
    "    distances.append(distance.euclidean(dict2numpy(cluster_center), sample))\n",
    "\n",
    "distances_unsorted = distances.copy()\n",
    "distances.sort()\n",
    "\n",
    "qty_distances_retrieve = math.ceil(len(distances) * slice_factor)\n",
    "distances_retrieve = distances[: qty_distances_retrieve]\n",
    "\n",
    "closest_samples_keys = [idx for idx, element in enumerate(distances_unsorted) if element in distances_retrieve]\n",
    "\n",
    "#x = [cluster_samples[k] for k in closest_samples_keys]\n",
    "\n",
    "#cluster_key_samples[[closest_samples_keys]]\n",
    "cluster_key_samples_closest = [cluster_key_samples[v] for k, v in enumerate(closest_samples_keys)]\n",
    "\n",
    "S2_1_DATASET_3_numpy =  S2_1_DATASET_3.to_numpy()[cluster_key_samples_closest]\n",
    "\n",
    "# treinando INCREMENTALMENTE o classificador\n",
    "\n",
    "for k, x in enumerate(S2_1_DATASET_3_numpy):\n",
    "    classifier.learn_one(numpy2dict(x), _class)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### predict (S2_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for k, x in S2_2.iloc[:, :-1].iterrows():\n",
    "    y_pred.append(classifier.predict_one(numpy2dict(x.to_numpy())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc DBSTREAM: 3.463203463203463%\n"
     ]
    }
   ],
   "source": [
    "res =  [(el, y_pred.count(el)) for el in y_pred]\n",
    "predicts_grouped = list(OrderedDict(res).items())\n",
    "\n",
    "for k, x in enumerate(predicts_grouped):\n",
    "    if x[0] == 35:\n",
    "        print('Acc DBSTREAM: ' + str(x[1] / S2_2.shape[0] * 100) + '%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### clusterer DBSCAN -> CLASSIFIER"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "cluster = 1\n",
    "_class = 35\n",
    "\n",
    "cluster_key_samples_match = [k for k, v in enumerate(dbscan.labels_) if v == cluster]\n",
    "\n",
    "S2_1_cluster_send_classifier = S2_1_DATASET_3.iloc[cluster_key_samples_match]\n",
    "\n",
    "# treinando INCREMENTALMENTE o classificador\n",
    "\n",
    "for k, x in S2_1_cluster_send_classifier.iterrows():\n",
    "    classifier.learn_one(numpy2dict(x.to_numpy()), _class)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### predict (S2_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for k, x in S2_2.iloc[:, :-1].iterrows():\n",
    "    y_pred.append(classifier.predict_one(numpy2dict(x.to_numpy())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc KNN RIVER: 38.52813852813853%\n"
     ]
    }
   ],
   "source": [
    "res =  [(el, y_pred.count(el)) for el in y_pred]\n",
    "predicts_grouped = list(OrderedDict(res).items())\n",
    "\n",
    "for k, x in enumerate(predicts_grouped):\n",
    "    if x[0] == 35:\n",
    "        print('Acc KNN RIVER: ' + str(x[1] / S2_2.shape[0] * 100) + '%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### clusterer DBSCAN -> CLASSIFIER KNN SCIKIT_MULTIFLOW"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "cluster = 1\n",
    "_class = 35\n",
    "\n",
    "cluster_key_samples_match = [k for k, v in enumerate(dbscan.labels_) if v == cluster]\n",
    "\n",
    "S2_1_cluster_send_classifier = S2_1_DATASET_3.iloc[cluster_key_samples_match]\n",
    "\n",
    "# treinando INCREMENTALMENTE o classificador\n",
    "\n",
    "for k, x in S2_1_cluster_send_classifier.iterrows():\n",
    "    classifier_knn_sk_mult.partial_fit(x.to_numpy().reshape(1, x.shape[0]), [_class])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### predict (S2_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for k, x in S2_2.iloc[:, :-1].iterrows():\n",
    "    y_pred.append(classifier_knn_sk_mult.predict(x.to_numpy().reshape(1,x.shape[0]))[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc KNN SCIKIT MULTILEARN: 48.917748917748916%\n"
     ]
    }
   ],
   "source": [
    "res =  [(el, y_pred.count(el)) for el in y_pred]\n",
    "predicts_grouped = list(OrderedDict(res).items())\n",
    "\n",
    "for k, x in enumerate(predicts_grouped):\n",
    "    if x[0] == 35:\n",
    "        print('Acc KNN SCIKIT MULTILEARN: ' + str(x[1] / S2_2.shape[0] * 100) + '%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. DETECTOR PHASE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "brickface (0) -> NORMAL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "NORMAL_x_train = S1_1.loc[S1_1['categorical_label'] == 0].iloc[:, :-1]\n",
    "NORMAL_x_test = S1_2.loc[S1_2['categorical_label'] == 0].iloc[:, :-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OvsO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from river import anomaly\n",
    "from river import preprocessing\n",
    "from river import multiclass\n",
    "from river import linear_model\n",
    "from river import tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "ovo = multiclass.OneVsOneClassifier(tree.HoeffdingAdaptiveTreeClassifier())\n",
    "model_ovo = scaler | ovo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "for k, x in NORMAL_x_train.iterrows():\n",
    "    model_ovo.learn_one(numpy2dict(x.to_numpy()), 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating: thread_id: pid_13652_id_1486881238472\n",
      "frame_id: 1487217562744\n",
      "scope: FRAME\n",
      "attrs: votes\tdefault_factory\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\JetBrains\\DataSpell 213.5352.7\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_vars.py\", line 286, in resolve_compound_variable_fields\n",
      "    return _typeName, resolver.get_dictionary(VariableWithOffset(var, offset) if offset else var)\n",
      "AttributeError: 'NoneType' object has no attribute 'get_dictionary'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-bd2e6e6f724b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mNORMAL_x_test\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miterrows\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[0mpprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_ovo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_one\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnumpy2dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\river\\compose\\pipeline.py\u001B[0m in \u001B[0;36mpredict_one\u001B[1;34m(self, x, learn_unsupervised)\u001B[0m\n\u001B[0;32m    400\u001B[0m         \"\"\"\n\u001B[0;32m    401\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfinal_step\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_transform_one\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlearn_unsupervised\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlearn_unsupervised\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 402\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mfinal_step\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_one\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    403\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    404\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpredict_proba_one\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlearn_unsupervised\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\JetBrains\\DataSpell 213.5352.7\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_trace_dispatch.py\u001B[0m in \u001B[0;36mtrace_dispatch\u001B[1;34m(py_db, frame, event, arg)\u001B[0m\n\u001B[0;32m     57\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0m_trace_dispatch\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0m_trace_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpy_db\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mImportError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.ThreadTracer.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\JetBrains\\DataSpell 213.5352.7\\plugins\\python-ce\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\JetBrains\\DataSpell 213.5352.7\\plugins\\python-ce\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1162\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for k, x in NORMAL_x_test.iterrows():\n",
    "    pprint(model_ovo.predict_one(numpy2dict(x.to_numpy())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from river import synth\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "from river import tree\n",
    "\n",
    "gen = synth.ConceptDriftStream(stream=synth.SEA(seed=42, variant=0),drift_stream=synth.SEA(seed=42, variant=1),seed=1, position=500, width=50)\n",
    "# Take 1000 instances from the infinite data generator\n",
    "dataset = iter(gen.take(1000))\n",
    "\n",
    "model = tree.HoeffdingAdaptiveTreeClassifier(grace_period=100,split_confidence=1e-5,leaf_prediction='nb',\n",
    "                                             nb_threshold=10,seed=0)\n",
    "\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HalfSpaceTree RIVER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Identificou 1.0101010101010102% de amostras NORMAIS corretamente'\n",
      "'Identificou 86.36363636363636% de amostras de falhas corretamente'\n"
     ]
    }
   ],
   "source": [
    "from river import preprocessing\n",
    "\n",
    "#HIPERPARÂMETROS\n",
    "qty_pred_normal = 0\n",
    "threshold = 0.75\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "model = anomaly.HalfSpaceTrees(seed=42, window_size=2, height=2, n_trees=5)\n",
    "\n",
    "for k, x in NORMAL_x_train.iterrows():\n",
    "    x_np = x.to_numpy()\n",
    "    data = x_np.reshape(1, x_np.shape[0])\n",
    "    scaled = minmax_scaler.partial_fit(data).transform(data)\n",
    "\n",
    "    model = model.learn_one(numpy2dict(scaled[0]))\n",
    "\n",
    "for k, x in NORMAL_x_test.iterrows():\n",
    "    x_np = x.to_numpy()\n",
    "    data = x_np.reshape(1, x_np.shape[0])\n",
    "    scaled = minmax_scaler.transform(data)\n",
    "\n",
    "    score = model.score_one(numpy2dict(scaled[0]))\n",
    "\n",
    "    if (score >= threshold):\n",
    "        qty_pred_normal = qty_pred_normal+1\n",
    "\n",
    "pprint('Identificou ' + str(qty_pred_normal/len(NORMAL_x_test)*100) + '% de amostras NORMAIS corretamente')\n",
    "\n",
    "qty_pred_falha = 0\n",
    "for k, x in S3.iloc[:, :-1].iterrows():\n",
    "    x_np = x.to_numpy()\n",
    "    data = x_np.reshape(1, x_np.shape[0])\n",
    "    scaled = minmax_scaler.transform(data)\n",
    "\n",
    "    score = model.score_one(numpy2dict(scaled[0]))\n",
    "\n",
    "    if (score < threshold):\n",
    "        qty_pred_falha = qty_pred_falha+1\n",
    "\n",
    "pprint('Identificou ' + str(qty_pred_falha/len(S3)*100) + '% de amostras de falhas corretamente')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Half Space Tree Sklearn Multiflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Identificou 0.0% de amostras NORMAIS corretamente'\n",
      "'Identificou 100.0% de amostras de falhas corretamente'\n"
     ]
    }
   ],
   "source": [
    "from skmultiflow.anomaly_detection import HalfSpaceTrees\n",
    "\n",
    "qty_pred_normal = 0\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "half_space_trees = HalfSpaceTrees(random_state=1, anomaly_threshold=0.5, window_size=2)\n",
    "\n",
    "for k, x in NORMAL_x_train.iterrows():\n",
    "    x_np = x.to_numpy()\n",
    "    data = x_np.reshape(1, x_np.shape[0])\n",
    "    scaled = minmax_scaler.partial_fit(data).transform(data)\n",
    "\n",
    "    half_space_trees.partial_fit(scaled)\n",
    "\n",
    "for k, x in NORMAL_x_test.iterrows():\n",
    "    x_np = x.to_numpy()\n",
    "    data = x_np.reshape(1, x_np.shape[0])\n",
    "    scaled = minmax_scaler.transform(data)\n",
    "\n",
    "    y_pred = half_space_trees.predict(scaled)\n",
    "\n",
    "    if (y_pred == 0):\n",
    "        qty_pred_normal = qty_pred_normal+1\n",
    "\n",
    "pprint('Identificou ' + str(qty_pred_normal/len(NORMAL_x_test)*100) + '% de amostras NORMAIS corretamente')\n",
    "\n",
    "qty_pred_falha = 0\n",
    "for k, x in S3.iloc[:, :-1].iterrows():\n",
    "    x_np = x.to_numpy()\n",
    "    data = x_np.reshape(1, x_np.shape[0])\n",
    "    scaled = minmax_scaler.transform(data)\n",
    "\n",
    "    y_pred = half_space_trees.predict(scaled)\n",
    "\n",
    "    if (y_pred == 1):\n",
    "        qty_pred_falha = qty_pred_falha+1\n",
    "\n",
    "pprint('Identificou ' + str(qty_pred_falha/len(S3)*100) + '% de amostras de falhas corretamente')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes Sklearn Multiflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Identificou 100.0% de amostras NORMAIS corretamente'\n",
      "'Identificou 100.0% de amostras de falhas corretamente'\n"
     ]
    }
   ],
   "source": [
    "from skmultiflow.bayes import NaiveBayes\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pca = PCA(.95)\n",
    "S1_x_pca = pd.DataFrame(pca.fit_transform(S1.iloc[:, :-2]).tolist())\n",
    "S1_x_pca_ss = pd.DataFrame(StandardScaler().fit_transform(S1_x_pca.to_numpy()))\n",
    "\n",
    "S1_x2_pca = pd.DataFrame(pca.fit_transform(S3.iloc[:, :-1]).tolist())\n",
    "S1_x2_pca_ss = pd.DataFrame(StandardScaler().fit_transform(S1_x2_pca.to_numpy()))\n",
    "\n",
    "qty_pred_normal = 0\n",
    "threshold = 0.5\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "nb = NaiveBayes()\n",
    "\n",
    "for k, x in S1_x_pca_ss.iterrows():\n",
    "    x_np = x.to_numpy()\n",
    "    data = x_np.reshape(1, x_np.shape[0])\n",
    "\n",
    "    nb.partial_fit(data, [0])\n",
    "\n",
    "for k, x in S1_x_pca_ss.iterrows():\n",
    "    x_np = x.to_numpy()\n",
    "    data = x_np.reshape(1, x_np.shape[0])\n",
    "\n",
    "    y_pred = nb.predict(data)\n",
    "\n",
    "    if (y_pred == 0):\n",
    "        qty_pred_normal = qty_pred_normal+1\n",
    "\n",
    "pprint('Identificou ' + str(qty_pred_normal/len(S1.iloc[:, -2])*100) + '% de amostras NORMAIS corretamente')\n",
    "\n",
    "qty_pred_falha = 0\n",
    "for k, x in S1_x2_pca_ss.iterrows():\n",
    "    x_np = x.to_numpy()\n",
    "    data = x_np.reshape(1, x_np.shape[0])\n",
    "\n",
    "    y_pred = nb.predict(data)[0]\n",
    "\n",
    "    if (y_pred != threshold):\n",
    "        qty_pred_falha = qty_pred_falha+1\n",
    "\n",
    "pprint('Identificou ' + str(qty_pred_falha/len(S3)*100) + '% de amostras de falhas corretamente')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OneClass SVM - SUPERVISIONADO (teste)\n",
    "\n",
    "Pode ser utilizado como linha de base para comparação desta fase!\n",
    "\n",
    "Resultados foram excelentes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Identificou 88.88888888888889% de amostras de normais corretamente'\n",
      "'Identificou 100.0% de amostras de falhas corretamente'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "ocsvm = OneClassSVM(gamma='auto')\n",
    "\n",
    "ocsvm.fit(S2_2.iloc[:, :-1])\n",
    "\n",
    "correct_normal = ocsvm.predict(S2_1.iloc[:, :-1])\n",
    "\n",
    "correct_normal_identified = 0\n",
    "for k, x in enumerate(correct_normal):\n",
    "    if (x == -1):\n",
    "        correct_normal_identified = correct_normal_identified+1\n",
    "\n",
    "pprint('Identificou ' + str(correct_normal_identified/len(correct_normal)*100) + '% de amostras de normais corretamente')\n",
    "\n",
    "predicts_failures = ocsvm.predict(S1.iloc[:, :-2])\n",
    "\n",
    "correct_failures_identified = 0\n",
    "for k, x in enumerate(predicts_failures):\n",
    "    if (x == -1):\n",
    "        correct_failures_identified = correct_failures_identified+1\n",
    "\n",
    "pprint('Identificou ' + str(correct_failures_identified/len(predicts_failures)*100) + '% de amostras de falhas corretamente')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Testes do Min Max SCALER Incremental"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-e5c72a22e8b2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'x'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'y'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m9\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'x'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'y'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m4.5\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'x'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'y'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m4.5\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'x'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m2.5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'y'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m4.5\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mscaler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMinMaxScaler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "# MinMax Scaler RIVER\n",
    "# FUNCIONA SOMENTE PARA 1 DIMENSAO\n",
    "\n",
    "X = [{'x': 0.0, 'y': 9}, {'x': 0.0, 'y': 4.5}, {'x': 5, 'y': 4.5}, {'x': 2.5, 'y': 4.5}]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "for x in X:\n",
    "    pprint(scaler.learn_one(x).transform_one(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 0., 10.]])\n",
      "array([[0., 0.]])\n",
      "array([[0., 0.]])\n",
      "array([[0., 0.]])\n",
      "array([[0., 0.]])\n",
      "array([[0., 0.]])\n",
      "array([[0., 0.]])\n",
      "array([[0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# MinMax Scikit Multiflow\n",
    "#NÃO FUNCIONA CORRETAMENTE\n",
    "\n",
    "from skmultiflow import transform\n",
    "\n",
    "wss = transform.WindowedMinmaxScaler(window_size=1)\n",
    "\n",
    "data = np.array([\n",
    "    [[0.0, 10]],\n",
    "    [[0.0, 5]],\n",
    "    [[0.0, 0]],\n",
    "    [[0.0, 5]],\n",
    "    [[0.0, 5]],\n",
    "    [[0.0, 20]],\n",
    "    [[10, 20]],\n",
    "    [[5, 5]]\n",
    "])\n",
    "\n",
    "for k, v in enumerate(data):\n",
    "    pprint(wss.partial_fit_transform(data[k]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0., 0.]])\n",
      "array([[0., 0.]])\n",
      "array([[0., 0.]])\n",
      "array([[0. , 0.5]])\n",
      "array([[0. , 0.5]])\n",
      "array([[0., 1.]])\n",
      "array([[1., 1.]])\n",
      "array([[0.5 , 0.25]])\n"
     ]
    }
   ],
   "source": [
    "# MinMax Scikit Learning\n",
    "# FUNCIONOU PERFEITO\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = np.array([\n",
    "                [[0.0, 10]],\n",
    "                [[0.0, 5]],\n",
    "                [[0.0, 0]],\n",
    "                [[0.0, 5]],\n",
    "                [[0.0, 5]],\n",
    "                [[0.0, 20]],\n",
    "                [[10, 20]],\n",
    "                [[5, 5]]\n",
    "])\n",
    "\n",
    "sk_scaler = MinMaxScaler()\n",
    "\n",
    "for k, v in enumerate(data):\n",
    "    pprint(sk_scaler.partial_fit(data[k]).transform(data[k]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}