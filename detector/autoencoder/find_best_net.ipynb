{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iCIoMaMTBg7l"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "'''\n",
    "EXTERNAL KERNEL\n",
    "'''\n",
    "google_colab = False\n",
    "kaggle = False\n",
    "\n",
    "'''\n",
    "CUDA\n",
    "'''\n",
    "cuda = False\n",
    "\n",
    "'''\n",
    "DATA REPRESENTATION\n",
    "\n",
    "1 => SINGLE READ | 2 => ADD FEATURES | 3 => WINDOW TO FEATURES\n",
    "'''\n",
    "DATA_REPRESENTATION = 2\n",
    "\n",
    "'''\n",
    "DOWNSAMPLE FACTOR\n",
    "\n",
    "1 => 10hz *original rate* | 2 => 5Hz | 5 => 2Hz | 10 => 1hz\n",
    "'''\n",
    "DOWNSAMPLE_FACTOR = 5\n",
    "\n",
    "'''\n",
    "WINDOWS LENGHT\n",
    "\n",
    "* needs divisor by datapoints target\n",
    "* considering downsample factor = 5\n",
    "\n",
    "1 => WINDOW DISABLED | 2 => 1 second | 4 => 2 seconds | 10 => 5 seconds | 20 => 10 seconds | 200 => 100 seconds *full flight*\n",
    "'''\n",
    "WINDOW_LENGHT =  1\n",
    "\n",
    "'''\n",
    "LIMITADOR\n",
    "\n",
    "Quantity of samples in the execution of the tests.\n",
    "'''\n",
    "LIMITADOR = 20000\n",
    "\n",
    "'''\n",
    "LOSS FACTOR [0,1]\n",
    "\n",
    "Ignores outliers in calculating the stats of losses in regenerated data.\n",
    "'''\n",
    "LOSS_FACTOR = 0.96\n",
    "\n",
    "'''\n",
    "TRAIN_SIZE [0,1]\n",
    "\n",
    "Percentage of samples to be trained\n",
    "'''\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "'''\n",
    "OUTPUT_FILE_NAME\n",
    "\n",
    "File with output results\n",
    "'''\n",
    "OUTPUT_FILE_NAME = 'output-dr_' + str(DATA_REPRESENTATION) + '-ts_' + str(TRAIN_SIZE) + '-lf_' + str.replace(str(LOSS_FACTOR), '.', '') + '-limit_' + str(LIMITADOR) + '-wl_' + str(WINDOW_LENGHT) + '.txt'\n",
    "\n",
    "'''\n",
    "PATH_OUTPUTS\n",
    "\n",
    "'''\n",
    "PATH_OUTPUTS = './outputs/'\n",
    "\n",
    "'''\n",
    "PATH_DATASET\n",
    "\n",
    "'''\n",
    "PATH_DATASET = '../../dataset/original/'\n",
    "\n",
    "'''\n",
    "FLUSH FILE\n",
    "\n",
    "If output results file is ON\n",
    "'''\n",
    "FLUSH_FILE = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CILVSdmV43uh",
    "outputId": "ccfdfad7-dc42-41e9-9c07-d4cfe527aa98"
   },
   "outputs": [],
   "source": [
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    path = '/content/drive/My Drive/ACADÊMICO/MESTRADO/DISSERTAÇÃO/CHAPTERS/5 EXPERIMENTO/dataset/data_representation_1'\n",
    "    dict_ds_original = {\n",
    "        'data_ds3_normal_t1_original' : pd.read_csv(path+'/F16_DS3_normal_t1.csv', header=None),\n",
    "        'data_ds3_normal_t2_original' : pd.read_csv(path+'/F16_DS3_normal_t2.csv', header=None),\n",
    "        'data_ds3_fault1_original' : pd.read_csv(path+'/F16_DS3_fault1_leakage.csv', header=None),\n",
    "        'data_ds3_fault2_original' : pd.read_csv(path+'/F16_DS3_fault2_viscousfriction.csv', header=None),\n",
    "        'data_ds3_fault3_original' : pd.read_csv(path+'/F16_DS3_fault3_compressibility.csv', header=None),\n",
    "        'data_ds3_fault4_original' : pd.read_csv(path+'/F16_DS3_fault4_fixedposition.csv', header=None),\n",
    "    }\n",
    "elif kaggle:\n",
    "    !conda install -y gdown\n",
    "    !gdown --id 1G88okIVmdcgLFlmd7rDRhHvHv98yK3UB\n",
    "    !gdown --id 1fX3utfHMjwKTt7IW4D01bnm-hv88yzrJ\n",
    "    !gdown --id 1yUG3R5zK2AIxtS9Q4Fk-udkKBZeYShgb\n",
    "    !gdown --id 1OBRDtuqNEZ-3Z-q0helWh2xGiAxeLACH\n",
    "    !gdown --id 17oDi60sWYsWHHxzj2aA9m6ARm8zQ81m_\n",
    "    !gdown --id 1jKEK4s5sYJh8PHtpHeV8ABOsHjuB26RA\n",
    "else:\n",
    "    dict_ds_original = {\n",
    "        'data_ds3_normal_t1_original' : pd.read_csv(PATH_DATASET+'F16_DS3_normal_t1.csv', header=None),\n",
    "        'data_ds3_normal_t2_original' : pd.read_csv(PATH_DATASET+'F16_DS3_normal_t2.csv', header=None),\n",
    "        'data_ds3_fault1_original' : pd.read_csv(PATH_DATASET+'F16_DS3_fault1_leakage.csv', header=None),\n",
    "        'data_ds3_fault2_original' : pd.read_csv(PATH_DATASET+'F16_DS3_fault2_viscousfriction.csv', header=None),\n",
    "        'data_ds3_fault3_original' : pd.read_csv(PATH_DATASET+'F16_DS3_fault3_compressibility.csv', header=None),\n",
    "        'data_ds3_fault4_original' : pd.read_csv(PATH_DATASET+'F16_DS3_fault4_fixedposition.csv', header=None),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dict_ds = dict_ds_original.copy()\n",
    "\n",
    "if dict_ds['data_ds3_normal_t1_original'].shape[0] % DOWNSAMPLE_FACTOR != 0 or dict_ds['data_ds3_fault1_original'].shape[0] % DOWNSAMPLE_FACTOR != 0:\n",
    "    raise Exception('Needs to be ?shape? divisor')\n",
    "\n",
    "for n, dataset_name in enumerate(dict_ds):\n",
    "    dataset = dict_ds[dataset_name].to_numpy()\n",
    "\n",
    "    downsampled = dataset[::DOWNSAMPLE_FACTOR]\n",
    "\n",
    "    x, y = downsampled.shape\n",
    "\n",
    "    # resample\n",
    "    dict_ds[dataset_name] = pd.DataFrame(downsampled.reshape((int(x/WINDOW_LENGHT),y*WINDOW_LENGHT)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# ADD COLUMNS WITH DIFF PREVIOUS VALUES\n",
    "\n",
    "if (DATA_REPRESENTATION == 2):\n",
    "    frame_size = int(1000/DOWNSAMPLE_FACTOR)\n",
    "\n",
    "    for n, dataset_name in enumerate(dict_ds):\n",
    "        dataset = dict_ds[dataset_name].to_numpy()\n",
    "\n",
    "        dimension = dataset.shape[1]\n",
    "        samples = dataset.shape[0]\n",
    "\n",
    "        # GENERATE NEW DIMENSIONS\n",
    "        dataset = np.concatenate((dataset, np.zeros((samples,dimension))), axis=1)\n",
    "\n",
    "        for f in np.arange(0,int(samples/frame_size)):\n",
    "            # OBTAIN THE FRAME FLIGHT\n",
    "            frame = dataset[f*frame_size:(f+1)*frame_size, 0:dimension]\n",
    "\n",
    "            # CALCULATE DIFFERENCE\n",
    "            chunk = np.diff(frame, axis=0)\n",
    "\n",
    "            # DONT CALCULATE THE DIFFERENCE FOR EACH FIRST TIMESTEP\n",
    "            chunk = np.insert(chunk, 0, frame[0, 0:dimension], axis=0)\n",
    "\n",
    "            # UPDATE DATASET WITH NEW FRAME INTO NEW DIMENSIONS\n",
    "            dataset[f*frame_size:(f+1)*frame_size,dimension:dimension*2] = chunk\n",
    "\n",
    "        dict_ds[dataset_name] = pd.DataFrame(dataset)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l5N9KYHoBg71"
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "data_ds3_t1_normal = dict_ds['data_ds3_normal_t1_original']\n",
    "data_ds3_t2_normal = dict_ds['data_ds3_normal_t2_original']\n",
    "data_ds3_fault1 = dict_ds['data_ds3_fault1_original']\n",
    "data_ds3_fault2 = dict_ds['data_ds3_fault2_original']\n",
    "data_ds3_fault3 = dict_ds['data_ds3_fault3_original']\n",
    "data_ds3_fault4 = dict_ds['data_ds3_fault4_original']\n",
    "\n",
    "# fit values\n",
    "ss.partial_fit(data_ds3_t1_normal)\n",
    "ss.partial_fit(data_ds3_t2_normal)\n",
    "ss.partial_fit(data_ds3_fault1)\n",
    "ss.partial_fit(data_ds3_fault2)\n",
    "ss.partial_fit(data_ds3_fault3)\n",
    "ss.partial_fit(data_ds3_fault4)\n",
    "\n",
    "# transform values\n",
    "data_ds3_t1_normal = ss.transform(data_ds3_t1_normal)\n",
    "data_ds3_t2_normal = ss.transform(data_ds3_t2_normal)\n",
    "data_ds3_fault1 = ss.transform(data_ds3_fault1)\n",
    "data_ds3_fault2 = ss.transform(data_ds3_fault2)\n",
    "data_ds3_fault3 = ss.transform(data_ds3_fault3)\n",
    "data_ds3_fault4 = ss.transform(data_ds3_fault4)\n",
    "\n",
    "# append normal labels\n",
    "data_ds3_t1_normal = np.append(data_ds3_t1_normal, np.zeros((data_ds3_t1_normal.shape[0],1)), axis = 1)\n",
    "data_ds3_t2_normal = np.append(data_ds3_t2_normal, np.zeros((data_ds3_t2_normal.shape[0],1)), axis = 1)\n",
    "\n",
    "# append fault labels\n",
    "def generate_fault_label(dataset, fault_label):\n",
    "    labels = np.array([[fault_label]]*dataset.shape[0])\n",
    "\n",
    "    return labels\n",
    "\n",
    "data_ds3_fault1 = np.append(data_ds3_fault1, generate_fault_label(data_ds3_fault1, 1), axis = 1)\n",
    "data_ds3_fault2 = np.append(data_ds3_fault2, generate_fault_label(data_ds3_fault2, 2), axis = 1)\n",
    "data_ds3_fault3 = np.append(data_ds3_fault3, generate_fault_label(data_ds3_fault3, 3), axis = 1)\n",
    "data_ds3_fault4 = np.append(data_ds3_fault4, generate_fault_label(data_ds3_fault4, 4), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aCbDYmvL43u2"
   },
   "outputs": [],
   "source": [
    "dimension = data_ds3_t2_normal.shape[1]-1\n",
    "\n",
    "# FUNCTIONS AND CLASSES\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encode_l, decode_l):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(encode_l)\n",
    "        self.decoder = nn.Sequential(decode_l)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "def run_train(net, train_loader, num_epochs, optimizer, loss_func):\n",
    "    train_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        losses = []\n",
    "        for n, (real_samples, _) in enumerate(train_loader):\n",
    "\n",
    "            net.zero_grad()\n",
    "\n",
    "            ### forward ###\n",
    "            if cuda:\n",
    "                output = net(real_samples.type(torch.FloatTensor).cuda())\n",
    "                loss = loss_func(output, real_samples.type(torch.FloatTensor).cuda())\n",
    "            else:\n",
    "                output = net(real_samples.type(torch.FloatTensor))\n",
    "                loss = loss_func(output, real_samples.type(torch.FloatTensor))\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            losses.append(loss.item)\n",
    "\n",
    "            ### backward ###\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        step_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(step_loss)\n",
    "\n",
    "        ### log ###\n",
    "        #print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss))\n",
    "\n",
    "    return net, output, train_loss, losses\n",
    "\n",
    "def generate_ground_truth(data_test):\n",
    "    ground_truth = []\n",
    "\n",
    "    for j, x in enumerate(data_test):\n",
    "\n",
    "        if x.shape[0] == dimension: # X_test\n",
    "            ground_truth.append(0)\n",
    "        else: # % others: get column label\n",
    "            if x[-1] != 0:\n",
    "                ground_truth.append(1)\n",
    "            else:\n",
    "                ground_truth.append(0)\n",
    "\n",
    "    return ground_truth\n",
    "\n",
    "def generate_losses(data_test, net, loss_function):\n",
    "    losses = []\n",
    "    #regenerate_data = np.zeros((1, dimension))\n",
    "    for j, x in enumerate(data_test):\n",
    "\n",
    "        if x.shape[0] > dimension:\n",
    "            x = x[:-1]\n",
    "\n",
    "        real = x.reshape(1,-1).astype(np.float32)\n",
    "\n",
    "        #regenerate_data[j] = regenerate.cpu().detach().numpy()\n",
    "\n",
    "        if cuda:\n",
    "            regenerate = net(torch.from_numpy(real).cuda())\n",
    "            loss_ae = loss_function(regenerate, torch.from_numpy(real).cuda()).item()\n",
    "        else:\n",
    "            regenerate = net(torch.from_numpy(real))\n",
    "            loss_ae = loss_function(regenerate, torch.from_numpy(real)).item()\n",
    "\n",
    "        losses.append(loss_ae)\n",
    "\n",
    "    return losses\n",
    "\n",
    "def generate_y_hat(losses, loss_threshold):\n",
    "    y_hat = []\n",
    "\n",
    "    for l in losses:\n",
    "        if l < loss_threshold:\n",
    "            y_hat.append(0)\n",
    "        else:\n",
    "            y_hat.append(1)\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "def tester(data_test, net, loss_function, loss_threshold = 1):\n",
    "\n",
    "    ground_truth = []\n",
    "    losses = []\n",
    "\n",
    "    for n, dataset_name in enumerate(data_test):\n",
    "        dataset = data_test[dataset_name]\n",
    "\n",
    "        ground_truth = ground_truth + generate_ground_truth(dataset)\n",
    "\n",
    "        losses = losses + generate_losses(dataset, net, loss_function)\n",
    "\n",
    "    y_hat = generate_y_hat(losses, loss_threshold)\n",
    "\n",
    "    return confusion_matrix(ground_truth, y_hat, normalize='true'), losses, ground_truth, y_hat\n",
    "\n",
    "def generate_encode_decode_layers(layers, output_layer):\n",
    "    od_encode = []\n",
    "    od_decode = []\n",
    "    # encode\n",
    "    for _, layer in enumerate(layers):\n",
    "        n = _ + 1\n",
    "\n",
    "        if (len(layers) == n):\n",
    "            break\n",
    "\n",
    "        od_encode.append(('l'+str((len(od_encode)+1)), nn.Linear(layers[_],layers[n])))\n",
    "\n",
    "        if (len(layers) != n+1):\n",
    "            od_encode.append(('l'+str((len(od_encode)+1)), nn.ReLU()))\n",
    "\n",
    "    # decode\n",
    "    layers.reverse()\n",
    "    for _, layer in enumerate(layers):\n",
    "        n = _ + 1\n",
    "\n",
    "        if (len(layers) == n):\n",
    "            break\n",
    "\n",
    "        od_decode.append(('l'+str((len(od_decode)+1)), nn.Linear(layers[_],layers[n])))\n",
    "\n",
    "        if (len(layers) != n+1):\n",
    "            od_decode.append(('l'+str((len(od_decode)+1)), nn.ReLU()))\n",
    "        else:\n",
    "            od_decode.append(('l'+str((len(od_decode)+1)), output_layer))\n",
    "\n",
    "    return OrderedDict(od_encode), OrderedDict(od_decode)\n",
    "\n",
    "def train(layers, last_layer, lr, epochs, batch_size, X_train, optim, loss_fnc, net = []):\n",
    "    encode_l, decode_l = generate_encode_decode_layers(layers, last_layer)\n",
    "\n",
    "    if (net == []):\n",
    "        net = Autoencoder(encode_l, decode_l)\n",
    "\n",
    "    if cuda:\n",
    "        net.cuda()\n",
    "\n",
    "    if (optim == 'ADAM'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    elif(optim == 'SGD'):\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    elif(optim == 'RMSprop'):\n",
    "        optimizer = torch.optim.RMSprop(net.parameters(), lr=lr)\n",
    "\n",
    "    torch.manual_seed(111)\n",
    "\n",
    "    # sets\n",
    "    train_set = [\n",
    "        (X_train, X_train) for i in range(len(X_train))\n",
    "    ]\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # train\n",
    "    net, output, loss, losses = run_train(net, train_loader, epochs, optimizer, loss_fnc)\n",
    "\n",
    "    return net, output, loss, losses, loss_fnc\n",
    "\n",
    "def test(X_train, X_test, net, loss_function, phi = 0):\n",
    "\n",
    "    faults = {'F1': data_ds3_fault1[:LIMITADOR],\n",
    "              'F2': data_ds3_fault2[:LIMITADOR],\n",
    "              'F3': data_ds3_fault3[:LIMITADOR],\n",
    "              'F4': data_ds3_fault4[:LIMITADOR]}\n",
    "\n",
    "    datas = {'X_TRAIN':X_train,\n",
    "             'X_TEST':X_test[:LIMITADOR],\n",
    "             'NORMAL 2':data_ds3_t2_normal[:LIMITADOR]}\n",
    "\n",
    "    datas.update(faults)\n",
    "\n",
    "    for n, dataset_name in enumerate(datas):\n",
    "        print('Losses ' + dataset_name , file=log)\n",
    "\n",
    "        if (dataset_name == 'X_TRAIN'):\n",
    "            losses = generate_losses(datas[dataset_name], net, loss_function)\n",
    "            np_losses = np.sort(np.array(losses))\n",
    "            losses = np_losses[:int(len(np_losses)*LOSS_FACTOR)]\n",
    "        else:\n",
    "            losses = [1]\n",
    "\n",
    "        print(\"mu: \", np.mean(losses), file=log)\n",
    "        print(\"std: \", np.std(losses, ddof=1, dtype=np.float64), file=log)\n",
    "\n",
    "        phi_test = np.mean(losses) + np.std(losses, ddof=1, dtype=np.float64)\n",
    "\n",
    "        print(\"phi: \", phi_test, file=log)\n",
    "\n",
    "        if (dataset_name == 'X_TRAIN'):\n",
    "            if phi == 0:\n",
    "                phi = phi_test\n",
    "\n",
    "        print('******************************', file=log)\n",
    "        print('******************************', file=log)\n",
    "        print('******************************', file=log)\n",
    "\n",
    "    # CONFUSION MATRIX FOR NORMAL_2\n",
    "    cf, losses, ground_truth, y_hat_n2 = tester({'NORMAL 2':data_ds3_t2_normal[:LIMITADOR]}, net, loss_function, phi)\n",
    "\n",
    "    print('NORMAL 2', file=log)\n",
    "    print(cf, file=log)\n",
    "    print('******************************', file=log)\n",
    "    print('******************************', file=log)\n",
    "    print('******************************', file=log)\n",
    "\n",
    "    for n, fault_name in enumerate(faults):\n",
    "\n",
    "        datas = {'X_TEST': X_test[:LIMITADOR],\n",
    "                 'fault_name': faults[fault_name][:LIMITADOR]}\n",
    "\n",
    "        cf, losses, ground_truth, y_hat = tester(datas, net, loss_function, phi)\n",
    "\n",
    "        print('X_TEST x ' + fault_name, file=log)\n",
    "        print(cf, file=log)\n",
    "        print('******************************', file=log)\n",
    "        print('******************************', file=log)\n",
    "        print('******************************', file=log)\n",
    "\n",
    "    return y_hat_n2, phi\n",
    "\n",
    "class Incremental_Stats():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.mu = 0.0\n",
    "        self.var = 0.0\n",
    "\n",
    "    def add(self, x):\n",
    "        if self.count == 0:\n",
    "            new_mu = x\n",
    "            new_var = 0\n",
    "        else:\n",
    "            new_mu = (self.count * self.mu + x) / (self.count + 1)\n",
    "            new_var = ((self.count + 1) / self.count) * (((self.count * self.var) / (self.count + 1)) + (((x - new_mu)**2) / self.count))\n",
    "\n",
    "        self.count = self.count+1\n",
    "        self.mu = new_mu\n",
    "        self.var = new_var\n",
    "\n",
    "        return self.mu, self.var, self.count\n",
    "\n",
    "    def get_mean(self):\n",
    "        return self.mean\n",
    "\n",
    "    def get_variance(self):\n",
    "        return self.variance\n",
    "\n",
    "    def get_std(self):\n",
    "        return self.variance**0.5\n",
    "\n",
    "    def get_n(self):\n",
    "        return self.Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_ds3_t1_normal[:, :-1], data_ds3_t1_normal[:, -1], test_size=1-TRAIN_SIZE, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBpHJcvJBg75",
    "outputId": "1c754107-785f-459d-ee5b-4dc524e468b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n",
      "*****************************************\n",
      "****************************************\n",
      "************ HYPERPARAMETERS ************\n",
      "****LIMITADOR**********************  5000\n",
      "****LOSS FACTOR********************  0.93\n",
      "[270, 128, 9]\n",
      "Tanh()\n",
      "32\n",
      "RMSprop\n",
      "L1Loss()\n",
      "*****************************************\n",
      "*****************************************\n",
      ".--\n",
      "0.11303801428875886\n",
      "0.15292845733815186\n",
      "--\n",
      "0.11130921468511223\n",
      "0.14394762643755604\n",
      "--\n",
      "0.11130921468511223\n",
      "0.14394762643755604\n",
      "Losses X_TRAIN\n",
      "mu:  0.07683092788495502\n",
      "std:  0.06374652780810533\n",
      "phi:  0.14057745569306035\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.8986 0.1014]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90666667 0.09333333]\n",
      " [0.8942     0.1058    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90666667 0.09333333]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90666667 0.09333333]\n",
      " [0.834      0.166     ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90666667 0.09333333]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.09250149234928863\n",
      "0.1450290645174746\n",
      "--\n",
      "0.09274905186146498\n",
      "0.14698881582650244\n",
      "--\n",
      "0.10202913327328861\n",
      "0.14573569092294703\n",
      "Losses X_TRAIN\n",
      "mu:  0.05753344830617658\n",
      "std:  0.056808115283072856\n",
      "phi:  0.11434156358924943\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9038 0.0962]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90972222 0.09027778]\n",
      " [0.9138     0.0862    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90972222 0.09027778]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90972222 0.09027778]\n",
      " [0.835      0.165     ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90972222 0.09027778]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.08239359612861234\n",
      "0.13824197796234225\n",
      "--\n",
      "0.07822275863029063\n",
      "0.13299868316061977\n",
      "--\n",
      "0.09409367505895595\n",
      "0.14203932501363137\n",
      "Losses X_TRAIN\n",
      "mu:  0.04887191514627009\n",
      "std:  0.05144092824296538\n",
      "phi:  0.10031284338923546\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9006 0.0994]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90638889 0.09361111]\n",
      " [0.9206     0.0794    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90638889 0.09361111]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90638889 0.09361111]\n",
      " [0.8018     0.1982    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90638889 0.09361111]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.076594644060242\n",
      "0.13773207259068307\n",
      "--\n",
      "0.07635815559700132\n",
      "0.14015801083129678\n",
      "--\n",
      "0.08965979519346728\n",
      "0.14176209480391933\n",
      "Losses X_TRAIN\n",
      "mu:  0.04316209053214286\n",
      "std:  0.050447727803437176\n",
      "phi:  0.09360981833558003\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9064 0.0936]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.91027778 0.08972222]\n",
      " [0.925      0.075     ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.91027778 0.08972222]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.91027778 0.08972222]\n",
      " [0.8242     0.1758    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.91027778 0.08972222]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.07604061575502985\n",
      "0.13688328376210768\n",
      "--\n",
      "0.07174820742383599\n",
      "0.12186377985490232\n",
      "--\n",
      "0.08607747763954103\n",
      "0.13818650813528505\n",
      "Losses X_TRAIN\n",
      "mu:  0.042921493536477805\n",
      "std:  0.05028061204423873\n",
      "phi:  0.09320210558071654\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.8974 0.1026]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90444444 0.09555556]\n",
      " [0.9126     0.0874    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90444444 0.09555556]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90444444 0.09555556]\n",
      " [0.697      0.303     ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90444444 0.09555556]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.07393041878550624\n",
      "0.13367422591100395\n",
      "--\n",
      "0.07766011353302747\n",
      "0.13619136239943805\n",
      "--\n",
      "0.08467458362178877\n",
      "0.1378804150370351\n",
      "Losses X_TRAIN\n",
      "mu:  0.041594632237252814\n",
      "std:  0.04953191543394266\n",
      "phi:  0.09112654767119548\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9062 0.0938]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.91111111 0.08888889]\n",
      " [0.9084     0.0916    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.91111111 0.08888889]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.91111111 0.08888889]\n",
      " [0.8426     0.1574    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.91111111 0.08888889]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.07162458055290497\n",
      "0.13264295608880886\n",
      "--\n",
      "0.06963528249226511\n",
      "0.12812219476280032\n",
      "--\n",
      "0.08252611203185682\n",
      "0.13662171870386314\n",
      "Losses X_TRAIN\n",
      "mu:  0.03952133756747365\n",
      "std:  0.04799946875957276\n",
      "phi:  0.08752080632704641\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9032 0.0968]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90944444 0.09055556]\n",
      " [0.897      0.103     ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90944444 0.09055556]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90944444 0.09055556]\n",
      " [0.8042     0.1958    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90944444 0.09055556]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.07228781878676575\n",
      "0.13194355187758375\n",
      "--\n",
      "0.07932521284837275\n",
      "0.14322842980427922\n",
      "--\n",
      "0.08212599963392131\n",
      "0.13745977666420806\n",
      "Losses X_TRAIN\n",
      "mu:  0.04032863343116163\n",
      "std:  0.048464843865448845\n",
      "phi:  0.08879347729661047\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9096 0.0904]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.9125 0.0875]\n",
      " [0.9306 0.0694]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.9125 0.0875]\n",
      " [0.     1.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.9125 0.0875]\n",
      " [0.8376 0.1624]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.9125 0.0875]\n",
      " [0.     1.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.07231361277951186\n",
      "0.13111027551773677\n",
      "--\n",
      "0.07168784568738193\n",
      "0.12795414647979622\n",
      "--\n",
      "0.08096620475097249\n",
      "0.13646895881040277\n",
      "Losses X_TRAIN\n",
      "mu:  0.04063084516308483\n",
      "std:  0.048901226104159506\n",
      "phi:  0.08953207126724433\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9022 0.0978]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90916667 0.09083333]\n",
      " [0.8934     0.1066    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90916667 0.09083333]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90916667 0.09083333]\n",
      " [0.818      0.182     ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90916667 0.09083333]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.06829581000036948\n",
      "0.13188412555766219\n",
      "--\n",
      "0.06749193517724052\n",
      "0.1331300709965463\n",
      "--\n",
      "0.0796187777935993\n",
      "0.1361922198759634\n",
      "Losses X_TRAIN\n",
      "mu:  0.03627632087145391\n",
      "std:  0.048584248633516035\n",
      "phi:  0.08486056950496995\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9026 0.0974]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90916667 0.09083333]\n",
      " [0.9206     0.0794    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90916667 0.09083333]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90916667 0.09083333]\n",
      " [0.8024     0.1976    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90916667 0.09083333]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.06864963458401488\n",
      "0.13108835475177077\n",
      "--\n",
      "0.0654065342079848\n",
      "0.1259297862512535\n",
      "--\n",
      "0.07832675564945252\n",
      "0.13534771930117298\n",
      "Losses X_TRAIN\n",
      "mu:  0.03680953711206333\n",
      "std:  0.04772211196702975\n",
      "phi:  0.08453164907909308\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9004 0.0996]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90805556 0.09194444]\n",
      " [0.8946     0.1054    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90805556 0.09194444]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90805556 0.09194444]\n",
      " [0.7972     0.2028    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90805556 0.09194444]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.0692376012811696\n",
      "0.12993305608206746\n",
      "--\n",
      "0.061004868892021474\n",
      "0.11188328513629912\n",
      "--\n",
      "0.07688326508633327\n",
      "0.13363164237784708\n",
      "Losses X_TRAIN\n",
      "mu:  0.03776896351977867\n",
      "std:  0.04714621058573643\n",
      "phi:  0.0849151741055151\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.8916 0.1084]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.9025 0.0975]\n",
      " [0.8654 0.1346]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.9025 0.0975]\n",
      " [0.     1.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.9025 0.0975]\n",
      " [0.684  0.316 ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.9025 0.0975]\n",
      " [0.     1.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.06604953788479583\n",
      "0.13029952721685786\n",
      "--\n",
      "0.06918987237056717\n",
      "0.13516558578832205\n",
      "--\n",
      "0.07629146564665895\n",
      "0.13376072950321571\n",
      "Losses X_TRAIN\n",
      "mu:  0.03441316262833338\n",
      "std:  0.04665651018301299\n",
      "phi:  0.08106967281134637\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9052 0.0948]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.91138889 0.08861111]\n",
      " [0.9216     0.0784    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.91138889 0.08861111]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.91138889 0.08861111]\n",
      " [0.8104     0.1896    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.91138889 0.08861111]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      ".--\n",
      "0.06593165946419402\n",
      "0.12918882515762375\n",
      "--\n",
      "0.06253901646053418\n",
      "0.123465025069669\n",
      "--\n",
      "0.07530914784765004\n",
      "0.13309474002355468\n",
      "Losses X_TRAIN\n",
      "mu:  0.0345635567643633\n",
      "std:  0.046465866742911185\n",
      "phi:  0.08102942350727449\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9002 0.0998]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90777778 0.09222222]\n",
      " [0.9014     0.0986    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90777778 0.09222222]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90777778 0.09222222]\n",
      " [0.7696     0.2304    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90777778 0.09222222]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "***************************\n",
      "Losses X_TRAIN\n",
      "mu:  0.0345635567643633\n",
      "std:  0.046465866742911185\n",
      "phi:  0.08102942350727449\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.9002 0.0998]\n",
      " [0.     0.    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.90777778 0.09222222]\n",
      " [0.9014     0.0986    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.90777778 0.09222222]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.90777778 0.09222222]\n",
      " [0.7696     0.2304    ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.90777778 0.09222222]\n",
      " [0.         1.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "architectures = [[54, 32, 9]]\n",
    "last_layers = [nn.Tanh()]\n",
    "batch_sizes = [32]\n",
    "optims = ['RMSprop']\n",
    "losses_fnc = [nn.L1Loss()]\n",
    "\n",
    "'''architectures = [[1080, 16], [1080, 9], [1080, 5], [1080, 3], [1080, 2],\n",
    "                 [1080, 32, 16], [1080, 32, 9], [1080, 32, 5], [1080, 32, 3], [1080, 32, 2],\n",
    "                 [1080, 64, 16], [1080, 64, 9], [1080, 64, 5], [1080, 64, 3], [1080, 64, 2],\n",
    "                 [1080, 128, 16], [1080, 128, 9], [1080, 128, 5], [1080, 128, 3], [1080, 128, 2],\n",
    "                 [1080, 256, 16], [1080, 256, 9], [1080, 256, 5], [1080, 256, 3], [1080, 256, 2],\n",
    "                 [1080, 512, 16], [1080, 512, 9], [1080, 512, 5], [1080, 512, 3], [1080, 512, 2],\n",
    "                 [1080, 64, 32, 16], [1080, 64, 32, 9], [1080, 64, 32, 5], [1080, 64, 32, 3], [1080, 64, 32, 2],\n",
    "                 [1080, 128, 64, 16], [1080, 128, 64, 9], [1080, 128, 64, 5], [1080, 128, 64, 3], [1080, 128, 64, 2],\n",
    "                 [1080, 256, 64, 16], [1080, 256, 64, 9], [1080, 256, 64, 5], [1080, 256, 64, 3], [1080, 256, 64, 2],\n",
    "                 [1080, 512, 64, 16], [1080, 512, 64, 9], [1080, 512, 64, 5], [1080, 512, 64, 3], [1080, 512, 64, 2],\n",
    "                 [1080, 512, 32, 16], [1080, 512, 32, 9], [1080, 512, 32, 5], [1080, 512, 32, 3], [1080, 512, 32, 2],\n",
    "                 [1080, 512, 32, 16, 9], [1080, 512, 32, 9, 5], [1080, 512, 32, 5, 2]]\n",
    "\n",
    "last_layers = [nn.Sigmoid(), nn.Tanh()]\n",
    "batch_sizes = [32]\n",
    "optims = ['ADAM', 'SGD', 'RMSprop']\n",
    "losses_fnc = [nn.BCEWithLogitsLoss(), nn.MSELoss() ,nn.L1Loss(), nn.BCELoss(), nn.SmoothL1Loss(), nn.PoissonNLLLoss()]'''\n",
    "\n",
    "EPOCHS = 1\n",
    "block_sizes = [1000]\n",
    "\n",
    "for block_size in block_sizes:\n",
    "    for optim in optims:\n",
    "        for batch_size in batch_sizes:\n",
    "            for last_layer in last_layers:\n",
    "                for architecture in architectures:\n",
    "                    for loss_fnc in losses_fnc:\n",
    "                        print('next')\n",
    "\n",
    "                        log = None\n",
    "                        if FLUSH_FILE:\n",
    "                            log = open(PATH_OUTPUTS+OUTPUT_FILE_NAME, \"a\", buffering=1)\n",
    "\n",
    "                        #BCE só SIGMOID\n",
    "                        if (type(loss_fnc) == type(nn.BCELoss()) and\n",
    "                            type(last_layer) != type(nn.Sigmoid())):\n",
    "                          continue\n",
    "\n",
    "                        print('*****************************************', file=log)\n",
    "                        print('****************************************', file=log)\n",
    "                        print('************ HYPERPARAMETERS ************', file=log)\n",
    "                        print('****LIMITADOR********************** ', LIMITADOR, file=log)\n",
    "                        print('****LOSS FACTOR******************** ', LOSS_FACTOR, file=log)\n",
    "                        print(architecture, file=log)\n",
    "                        print(last_layer, file=log)\n",
    "                        print(batch_size, file=log)\n",
    "                        print(optim, file=log)\n",
    "                        print(loss_fnc, file=log)\n",
    "                        print('*****************************************', file=log)\n",
    "                        print('*****************************************', file=log)\n",
    "                        block_train = int(X_train.shape[0] / block_size)\n",
    "                        net = []\n",
    "                        count = 0\n",
    "                        agg_loss = []\n",
    "                        for n in np.arange(0, block_train):\n",
    "                            print('.', end=\"\")\n",
    "                            count = count+1\n",
    "\n",
    "                            if block_size*(n+1) < X_train.shape[0]:\n",
    "                                data = X_train[block_size * n : block_size*(n+1)]\n",
    "                            else:\n",
    "                                data = X_train[block_size * n:]\n",
    "\n",
    "                            net, output, loss, losses, loss_function = train(layers=architecture.copy(), last_layer=last_layer, lr=1e-3, epochs=EPOCHS, batch_size=batch_size, X_train=data, optim=optim, loss_fnc=loss_fnc, net=net)\n",
    "\n",
    "                            losses_geral_step = generate_losses(data_test=X_train, net=net, loss_function=loss_fnc)\n",
    "                            print('--')\n",
    "                            print(np.mean(losses_geral_step))\n",
    "                            print(np.std(losses_geral_step, ddof=1, dtype=np.float64))\n",
    "\n",
    "                            losses_batch_step = generate_losses(data_test=data, net=net, loss_function=loss_fnc)\n",
    "                            print('--')\n",
    "                            print(np.mean(losses_batch_step))\n",
    "                            print(np.std(losses_batch_step, ddof=1, dtype=np.float64))\n",
    "                            agg_loss = np.concatenate((agg_loss, losses_batch_step), axis = 0)\n",
    "                            phi_batch_step = np.mean(losses_batch_step) + np.std(losses_batch_step, ddof=1, dtype=np.float64)\n",
    "\n",
    "                            print('--')\n",
    "                            print(np.mean(agg_loss))\n",
    "                            print(np.std(agg_loss, ddof=1, dtype=np.float64))\n",
    "\n",
    "                            _, _ = test(X_train, X_test, net, loss_function, phi_batch_step)\n",
    "\n",
    "                            print('***************************')\n",
    "                            print('***************************')\n",
    "                            print('***************************')\n",
    "                            print('***************************')\n",
    "\n",
    "                        phi = np.mean(losses_batch_step) + np.std(losses_batch_step, ddof=1, dtype=np.float64)\n",
    "                        y_hat_n2, phi = test(X_train, X_test, net, loss_function, phi)\n",
    "\n",
    "                        if FLUSH_FILE:\n",
    "                            log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses X_TRAIN\n",
      "mu:  0.6927304235736975\n",
      "std:  0.002546590776994526\n",
      "phi:  0.695277014350692\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  nan\n",
      "phi:  nan\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "C:\\Users\\MARCELO\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL 2\n",
      "[[0.838 0.162]\n",
      " [0.    0.   ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.8 0.2]\n",
      " [0.  1. ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.8 0.2]\n",
      " [0.  1. ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.8 0.2]\n",
      " [0.  1. ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.8 0.2]\n",
      " [0.  1. ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "y_hat_n2, phi = test(X_train, X_test, net, loss_function)\n",
    "\n",
    "np.nanstd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "cf, losses, ground_truth, y_hat = tester({'normal_1': data_ds3_t2_normal}, net, loss_function, loss_threshold = .6919097)\n",
    "\n",
    "losses = generate_losses(X_train, net, loss_function)\n",
    "np_losses = np.sort(np.array(losses))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6926565\n",
      "0.0028047627\n",
      "0.6922134\n"
     ]
    }
   ],
   "source": [
    "losses = np_losses[:int(len(np_losses)*1)]\n",
    "print(np.mean(losses))\n",
    "print(np.std(losses, ddof=1, dtype=np.float64))\n",
    "print(np.median(losses))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from scipy import stats, signal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "real = X_train[15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.normal(size=1000)\n",
    "plt.hist(losses, density=True, bins=200)  # `density=False` would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9027544260025024\n",
      "5.552284667977758e-21\n"
     ]
    }
   ],
   "source": [
    "shapiro_test = stats.shapiro(losses)\n",
    "print(shapiro_test.statistic)\n",
    "print(shapiro_test.pvalue)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0, 0)\n",
      "(3.0, 2.0, 1.4142135623730951)\n",
      "(4.0, 4.0, 2.0)\n",
      "(5.0, 6.666666666666667, 2.581988897471611)\n",
      "(6.0, 10.0, 3.1622776601683795)\n",
      "(2, 0, 0)\n",
      "(3.0, 2.0, 1.4142135623730951)\n"
     ]
    },
    {
     "data": {
      "text/plain": "3.1622776601683795"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "'''def incremental_stats(x):\n",
    "\n",
    "    global K, Elements, Ex, Ex2\n",
    "    if Elements == 0:\n",
    "        K = x\n",
    "    Elements += 1\n",
    "    Ex += x - K\n",
    "    Ex2 += (x - K) * (x - K)\n",
    "\n",
    "    if (Elements>1):\n",
    "        mean = K + Ex / Elements\n",
    "        variance = (Ex2 - (Ex * Ex) / Elements) / (Elements - 1)\n",
    "\n",
    "        return mean, variance\n",
    "\n",
    "    return x, 0'''\n",
    "\n",
    "inc_stats = Incremental_Stats()\n",
    "\n",
    "print(inc_stats.add(2))\n",
    "print(inc_stats.add(4))\n",
    "print(inc_stats.add(6))\n",
    "print(inc_stats.add(8))\n",
    "print(inc_stats.add(10))\n",
    "\n",
    "inc_stats = Incremental_Stats()\n",
    "print(inc_stats.add(2))\n",
    "print(inc_stats.add(4))\n",
    "\n",
    "a = [2,4,6,8,10]\n",
    "np.std(a, ddof=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "regenerate = net(torch.from_numpy(real.reshape(1,-1).astype(np.float32))).cpu().detach().numpy().reshape(-1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(real, 'b')\n",
    "plt.plot(regenerate, 'r')\n",
    "plt.fill_between(np.arange(27), regenerate.reshape(1,-1)[0], real.reshape(1,-1)[0], color='lightcoral')\n",
    "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [],
   "source": [
    "erros = (regenerate.reshape(1,-1)[0] - real.reshape(1,-1)[0])**2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9406610680591991"
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(erros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PHASE 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses X_TRAIN\n",
      "mu:  0.44753674\n",
      "std:  0.20366928\n",
      "phi:  0.651206\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses X_TEST\n",
      "mu:  1.0\n",
      "std:  0.0\n",
      "phi:  1.0\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses NORMAL 2\n",
      "mu:  1.0\n",
      "std:  0.0\n",
      "phi:  1.0\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F1\n",
      "mu:  1.0\n",
      "std:  0.0\n",
      "phi:  1.0\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F2\n",
      "mu:  1.0\n",
      "std:  0.0\n",
      "phi:  1.0\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F3\n",
      "mu:  1.0\n",
      "std:  0.0\n",
      "phi:  1.0\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Losses F4\n",
      "mu:  1.0\n",
      "std:  0.0\n",
      "phi:  1.0\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "NORMAL 2\n",
      "[[0.99833333 0.00166667]\n",
      " [0.         0.        ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F1\n",
      "[[0.99866667 0.00133333]\n",
      " [0.99833333 0.00166667]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F2\n",
      "[[0.99866667 0.00133333]\n",
      " [0.021      0.979     ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F3\n",
      "[[0.99866667 0.00133333]\n",
      " [0.15366667 0.84633333]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "X_TEST x F4\n",
      "[[0.99866667 0.00133333]\n",
      " [0.064      0.936     ]]\n",
      "******************************\n",
      "******************************\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "log = None\n",
    "y_hat_n2, phi = test(X_train[:1000], X_test, net, loss_function)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [],
   "source": [
    "y_hat_n2 = np.array(X_train[:1000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok 0.0 %\n",
      "incorrect 0.0 %\n"
     ]
    }
   ],
   "source": [
    "eq0 = np.where(y_hat_n2 == 0)[0] #ok\n",
    "eq1 = np.where(y_hat_n2 == 1)[0] #incorrect\n",
    "\n",
    "print('ok', len(eq0)/len(X_train[:1000]), '%')\n",
    "print('incorrect', len(eq1)/len(X_train[:1000]), '%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1], loss:0.6985\n"
     ]
    }
   ],
   "source": [
    "log = open(path+'/output_retrain.txt', \"a\", buffering=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_ds3_t2_normal[eq1, :-1], data_ds3_t2_normal[eq1, :-1], test_size=0.2, random_state=42)\n",
    "\n",
    "architectures = [[dimension,128,9]]\n",
    "last_layers = [nn.Sigmoid()]\n",
    "batch_sizes = [32]\n",
    "optims = ['ADAM']\n",
    "losses_fnc = [nn.BCEWithLogitsLoss()]\n",
    "\n",
    "for architecture in architectures:\n",
    "    for optim in optims:\n",
    "        for batch_size in batch_sizes:\n",
    "            for last_layer in last_layers:\n",
    "                for loss_fnc in losses_fnc:\n",
    "\n",
    "                    #BCE só SIGMOID\n",
    "                    if (type(loss_fnc) == type(nn.BCELoss()) and\n",
    "                            type(last_layer) != type(nn.Sigmoid())):\n",
    "                        continue\n",
    "\n",
    "                    print('*****************************************', file=log)\n",
    "                    print('****************************************', file=log)\n",
    "                    print('************ HYPERPARAMETERS ************', file=log)\n",
    "                    print('*****************************************', file=log)\n",
    "                    print('*****************************************', file=log)\n",
    "                    print(architecture, file=log)\n",
    "                    print(last_layer, file=log)\n",
    "                    print(batch_size, file=log)\n",
    "                    print(optim, file=log)\n",
    "                    print(loss_fnc, file=log)\n",
    "                    print('*****************************************', file=log)\n",
    "                    print('*****************************************', file=log)\n",
    "\n",
    "                    net, output, loss, losses, loss_function = train(layers=architecture.copy(), last_layer=last_layer, lr=1e-3, epochs=1, batch_size=batch_size, X_train=X_train, optim=optim, loss_fnc=loss_fnc, net=net)\n",
    "\n",
    "                    _, phi = test(np.concatenate((X_train, data_ds3_t1_normal[:,:-1])), data_ds3_t1_normal, net, loss_function)\n",
    "\n",
    "log.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "log = open(path+'/output_retrain.txt', \"a\", buffering=1)\n",
    "_, phi = test(X_train, data_ds3_t1_normal, net, loss_function) #x_train, x_test, net, loss_fnc ### X_TRAIN precisa conter os dados históricos\n",
    "log.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal 0.9122222222222223 %\n",
      "anomaly 0.08777777777777777 %\n"
     ]
    }
   ],
   "source": [
    "cf, losses, ground_truth, y_hat = tester({'normal_1': data_ds3_t2_normal}, net, loss_function, loss_threshold = .6919097)\n",
    "\n",
    "y_hat = np.array(y_hat)\n",
    "\n",
    "eq0 = np.where(y_hat == 0)[0] #ok\n",
    "eq1 = np.where(y_hat == 1)[0] #incorrect\n",
    "\n",
    "print('normal', len(eq0)/len(y_hat), '%')\n",
    "print('anomaly', len(eq1)/len(y_hat), '%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Gqgs-kDf43u_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}