{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from river import anomaly, preprocessing, compose, ensemble, neighbors, datasets\n",
    "from river.utils import numpy2dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "'''\n",
    "EXTERNAL KERNEL\n",
    "'''\n",
    "google_colab = False\n",
    "kaggle = False\n",
    "\n",
    "'''\n",
    "CUDA\n",
    "'''\n",
    "cuda = False\n",
    "\n",
    "'''\n",
    "DATA REPRESENTATION\n",
    "\n",
    "1 => SINGLE READ | 2 => ADD FEATURES | 3 => WINDOW TO FEATURES\n",
    "'''\n",
    "DATA_REPRESENTATION = 1\n",
    "\n",
    "'''\n",
    "DOWNSAMPLE FACTOR\n",
    "\n",
    "1 => 10hz *original rate* | 2 => 5Hz | 5 => 2Hz | 10 => 1hz\n",
    "'''\n",
    "DOWNSAMPLE_FACTOR = 5\n",
    "\n",
    "'''\n",
    "WINDOWS LENGHT\n",
    "\n",
    "* needs divisor by datapoints target\n",
    "* considering downsample factor = 5\n",
    "\n",
    "1 => WINDOW DISABLED | 2 => 1 second | 4 => 2 seconds | 10 => 5 seconds | 20 => 10 seconds | 200 => 100 seconds *full flight*\n",
    "'''\n",
    "WINDOW_LENGHT =  1\n",
    "\n",
    "'''\n",
    "LIMITADOR\n",
    "\n",
    "Quantity of samples in the execution of the tests.\n",
    "'''\n",
    "LIMITADOR = 20000\n",
    "\n",
    "'''\n",
    "LOSS FACTOR [0,1]\n",
    "\n",
    "Ignores outliers in calculating the stats of losses in regenerated data.\n",
    "'''\n",
    "LOSS_FACTOR = 1\n",
    "\n",
    "'''\n",
    "TRAIN_SIZE [0,1]\n",
    "\n",
    "Percentage of samples to be trained\n",
    "'''\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "'''\n",
    "OUTPUT_FILE_NAME\n",
    "\n",
    "File with output results\n",
    "'''\n",
    "OUTPUT_FILE_NAME = 'output_sgdocsvm_dr_' + str(DATA_REPRESENTATION) + '-ts_' + str(TRAIN_SIZE) + '-lf_' + str.replace(str(LOSS_FACTOR), '.', '') + '-limit_' + str(LIMITADOR) + '-wl_' + str(WINDOW_LENGHT) + '.txt'\n",
    "\n",
    "'''\n",
    "PATH_OUTPUTS\n",
    "\n",
    "'''\n",
    "PATH_OUTPUTS = './outputs/'\n",
    "\n",
    "'''\n",
    "PATH_DATASET\n",
    "\n",
    "'''\n",
    "PATH_DATASET = '../../dataset/original/'\n",
    "\n",
    "'''\n",
    "FLUSH FILE\n",
    "\n",
    "If output results file is ON\n",
    "'''\n",
    "FLUSH_FILE = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    path = '/content/drive/My Drive/ACADÊMICO/MESTRADO/DISSERTAÇÃO/CHAPTERS/5 EXPERIMENTO/dataset/data_representation_1'\n",
    "    dict_ds_original = {\n",
    "        'data_ds3_normal_t1_original' : pd.read_csv(path+'/F16_DS3_normal_t1.csv', header=None),\n",
    "        'data_ds3_normal_t2_original' : pd.read_csv(path+'/F16_DS3_normal_t2.csv', header=None),\n",
    "        'data_ds3_fault1_original' : pd.read_csv(path+'/F16_DS3_fault1_leakage.csv', header=None),\n",
    "        'data_ds3_fault2_original' : pd.read_csv(path+'/F16_DS3_fault2_viscousfriction.csv', header=None),\n",
    "        'data_ds3_fault3_original' : pd.read_csv(path+'/F16_DS3_fault3_compressibility.csv', header=None),\n",
    "        'data_ds3_fault4_original' : pd.read_csv(path+'/F16_DS3_fault4_fixedposition.csv', header=None),\n",
    "    }\n",
    "elif kaggle:\n",
    "    !conda install -y gdown\n",
    "    !gdown --id 1G88okIVmdcgLFlmd7rDRhHvHv98yK3UB\n",
    "    !gdown --id 1fX3utfHMjwKTt7IW4D01bnm-hv88yzrJ\n",
    "    !gdown --id 1yUG3R5zK2AIxtS9Q4Fk-udkKBZeYShgb\n",
    "    !gdown --id 1OBRDtuqNEZ-3Z-q0helWh2xGiAxeLACH\n",
    "    !gdown --id 17oDi60sWYsWHHxzj2aA9m6ARm8zQ81m_\n",
    "    !gdown --id 1jKEK4s5sYJh8PHtpHeV8ABOsHjuB26RA\n",
    "else:\n",
    "    dict_ds_original = {\n",
    "        'data_ds3_normal_t1_original' : pd.read_csv(PATH_DATASET+'F16_DS3_normal_t1.csv', header=None),\n",
    "        'data_ds3_normal_t2_original' : pd.read_csv(PATH_DATASET+'F16_DS3_normal_t2.csv', header=None),\n",
    "        'data_ds3_fault1_original' : pd.read_csv(PATH_DATASET+'F16_DS3_fault1_leakage.csv', header=None),\n",
    "        'data_ds3_fault2_original' : pd.read_csv(PATH_DATASET+'F16_DS3_fault2_viscousfriction.csv', header=None),\n",
    "        'data_ds3_fault3_original' : pd.read_csv(PATH_DATASET+'F16_DS3_fault3_compressibility.csv', header=None),\n",
    "        'data_ds3_fault4_original' : pd.read_csv(PATH_DATASET+'F16_DS3_fault4_fixedposition.csv', header=None),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "dict_ds = dict_ds_original.copy()\n",
    "\n",
    "if dict_ds['data_ds3_normal_t1_original'].shape[0] % DOWNSAMPLE_FACTOR != 0 or dict_ds['data_ds3_fault1_original'].shape[0] % DOWNSAMPLE_FACTOR != 0:\n",
    "    raise Exception('Needs to be ?shape? divisor')\n",
    "\n",
    "for n, dataset_name in enumerate(dict_ds):\n",
    "    dataset = dict_ds[dataset_name].to_numpy()\n",
    "\n",
    "    downsampled = dataset[::DOWNSAMPLE_FACTOR]\n",
    "\n",
    "    x, y = downsampled.shape\n",
    "\n",
    "    # resample\n",
    "    dict_ds[dataset_name] = pd.DataFrame(downsampled.reshape((int(x/WINDOW_LENGHT),y*WINDOW_LENGHT)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# ADD COLUMNS WITH DIFF PREVIOUS VALUES\n",
    "\n",
    "if (DATA_REPRESENTATION == 2):\n",
    "    frame_size = int(1000/DOWNSAMPLE_FACTOR)\n",
    "\n",
    "    for n, dataset_name in enumerate(dict_ds):\n",
    "        dataset = dict_ds[dataset_name].to_numpy()\n",
    "\n",
    "        dimension = dataset.shape[1]\n",
    "        samples = dataset.shape[0]\n",
    "\n",
    "        # GENERATE NEW DIMENSIONS\n",
    "        dataset = np.concatenate((dataset, np.zeros((samples,dimension))), axis=1)\n",
    "\n",
    "        for f in np.arange(0,int(samples/frame_size)):\n",
    "            # OBTAIN THE FRAME FLIGHT\n",
    "            frame = dataset[f*frame_size:(f+1)*frame_size, 0:dimension]\n",
    "\n",
    "            # CALCULATE DIFFERENCE\n",
    "            chunk = np.diff(frame, axis=0)\n",
    "\n",
    "            # DONT CALCULATE THE DIFFERENCE FOR EACH FIRST TIMESTEP\n",
    "            chunk = np.insert(chunk, 0, frame[0, 0:dimension], axis=0)\n",
    "\n",
    "            # UPDATE DATASET WITH NEW FRAME INTO NEW DIMENSIONS\n",
    "            dataset[f*frame_size:(f+1)*frame_size,dimension:dimension*2] = chunk\n",
    "\n",
    "        dict_ds[dataset_name] = pd.DataFrame(dataset)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "data_ds3_t1_normal = dict_ds['data_ds3_normal_t1_original']\n",
    "data_ds3_t2_normal = dict_ds['data_ds3_normal_t2_original']\n",
    "data_ds3_fault1 = dict_ds['data_ds3_fault1_original']\n",
    "data_ds3_fault2 = dict_ds['data_ds3_fault2_original']\n",
    "data_ds3_fault3 = dict_ds['data_ds3_fault3_original']\n",
    "data_ds3_fault4 = dict_ds['data_ds3_fault4_original']\n",
    "\n",
    "# fit values\n",
    "ss.partial_fit(data_ds3_t1_normal)\n",
    "ss.partial_fit(data_ds3_t2_normal)\n",
    "ss.partial_fit(data_ds3_fault1)\n",
    "ss.partial_fit(data_ds3_fault2)\n",
    "ss.partial_fit(data_ds3_fault3)\n",
    "ss.partial_fit(data_ds3_fault4)\n",
    "\n",
    "# transform values\n",
    "data_ds3_t1_normal = ss.transform(data_ds3_t1_normal)\n",
    "data_ds3_t2_normal = ss.transform(data_ds3_t2_normal)\n",
    "data_ds3_fault1 = ss.transform(data_ds3_fault1)\n",
    "data_ds3_fault2 = ss.transform(data_ds3_fault2)\n",
    "data_ds3_fault3 = ss.transform(data_ds3_fault3)\n",
    "data_ds3_fault4 = ss.transform(data_ds3_fault4)\n",
    "\n",
    "# append normal labels\n",
    "data_ds3_t1_normal = np.append(data_ds3_t1_normal, np.zeros((data_ds3_t1_normal.shape[0],1)), axis = 1)\n",
    "data_ds3_t2_normal = np.append(data_ds3_t2_normal, np.zeros((data_ds3_t2_normal.shape[0],1)), axis = 1)\n",
    "\n",
    "# append fault labels\n",
    "def generate_fault_label(dataset, fault_label):\n",
    "    labels = np.array([[fault_label]]*dataset.shape[0])\n",
    "\n",
    "    return labels\n",
    "\n",
    "data_ds3_fault1 = np.append(data_ds3_fault1, generate_fault_label(data_ds3_fault1, 1), axis = 1)\n",
    "data_ds3_fault2 = np.append(data_ds3_fault2, generate_fault_label(data_ds3_fault2, 2), axis = 1)\n",
    "data_ds3_fault3 = np.append(data_ds3_fault3, generate_fault_label(data_ds3_fault3, 3), axis = 1)\n",
    "data_ds3_fault4 = np.append(data_ds3_fault4, generate_fault_label(data_ds3_fault4, 4), axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def verify_inliers(scores, threshold):\n",
    "    inliers_detected = 0\n",
    "\n",
    "    for score in scores:\n",
    "        if (score <= threshold): #low score - normal observation\n",
    "            inliers_detected = inliers_detected+1\n",
    "\n",
    "    print((inliers_detected/len(scores))*100, file=log)\n",
    "\n",
    "def verify_outliers(scores, threshold):\n",
    "    outliers_detected = 0\n",
    "\n",
    "    for score in scores:\n",
    "        if (score > threshold): #high score - outlier observation\n",
    "            outliers_detected = outliers_detected+1\n",
    "\n",
    "    print((outliers_detected/len(scores))*100, file=log)\n",
    "\n",
    "def calculate_score(clf, datas):\n",
    "    scores = []\n",
    "\n",
    "    for k, x in enumerate(datas):\n",
    "        scores.append(clf.score_one(numpy2dict(x)))\n",
    "\n",
    "    return scores\n",
    "\n",
    "ocsvm_river_p = {\n",
    "    'nu': [0],\n",
    "    'threshold': [0.5, 0.4, 0.3, 0.2, 0.1, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_ds3_t1_normal[:, :-1], data_ds3_t1_normal[:, -1], test_size=1-TRAIN_SIZE, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".OneClassSVM 0 0.5\n",
      "X_TEST\n",
      "33308 36000\n",
      "92.52222222222221\n",
      "NORMAL_2\n",
      "19055 20000\n",
      "95.275\n",
      "F1\n",
      "28.95\n",
      "F2\n",
      "1.49\n",
      "F3\n",
      "1.7950000000000002\n",
      "F4\n",
      "1.505\n",
      "OneClassSVM 0 0.4\n",
      "X_TEST\n",
      "31342 36000\n",
      "87.06111111111112\n",
      "NORMAL_2\n",
      "18173 20000\n",
      "90.865\n",
      "F1\n",
      "65.375\n",
      "F2\n",
      "1.49\n",
      "F3\n",
      "1.9\n",
      "F4\n",
      "1.51\n",
      "OneClassSVM 0 0.3\n",
      "X_TEST\n",
      "23039 36000\n",
      "63.99722222222223\n",
      "NORMAL_2\n",
      "15136 20000\n",
      "75.68\n",
      "F1\n",
      "86.055\n",
      "F2\n",
      "1.4949999999999999\n",
      "F3\n",
      "2.375\n",
      "F4\n",
      "1.775\n",
      "OneClassSVM 0 0.2\n",
      "X_TEST\n",
      "4053 36000\n",
      "11.258333333333333\n",
      "NORMAL_2\n",
      "4818 20000\n",
      "24.09\n",
      "F1\n",
      "91.57\n",
      "F2\n",
      "1.4949999999999999\n",
      "F3\n",
      "4.165\n",
      "F4\n",
      "2.915\n",
      "OneClassSVM 0 0.1\n",
      "X_TEST\n",
      "2044 36000\n",
      "5.677777777777778\n",
      "NORMAL_2\n",
      "1963 20000\n",
      "9.815\n",
      "F1\n",
      "94.69999999999999\n",
      "F2\n",
      "1.5\n",
      "F3\n",
      "7.969999999999999\n",
      "F4\n",
      "5.395\n",
      "OneClassSVM 0 0.6\n",
      "X_TEST\n",
      "34563 36000\n",
      "96.00833333333333\n",
      "NORMAL_2\n",
      "19510 20000\n",
      "97.55\n",
      "F1\n",
      "16.85\n",
      "F2\n",
      "1.49\n",
      "F3\n",
      "1.685\n",
      "F4\n",
      "1.5\n",
      "OneClassSVM 0 0.7\n",
      "X_TEST\n",
      "35128 36000\n",
      "97.57777777777777\n",
      "NORMAL_2\n",
      "19619 20000\n",
      "98.095\n",
      "F1\n",
      "10.27\n",
      "F2\n",
      "1.49\n",
      "F3\n",
      "1.585\n",
      "F4\n",
      "1.5\n",
      "OneClassSVM 0 0.8\n",
      "X_TEST\n",
      "35321 36000\n",
      "98.1138888888889\n",
      "NORMAL_2\n",
      "19645 20000\n",
      "98.225\n",
      "F1\n",
      "7.2700000000000005\n",
      "F2\n",
      "1.49\n",
      "F3\n",
      "1.485\n",
      "F4\n",
      "1.5\n",
      "OneClassSVM 0 0.9\n",
      "X_TEST\n",
      "35386 36000\n",
      "98.29444444444444\n",
      "NORMAL_2\n",
      "19675 20000\n",
      "98.375\n",
      "F1\n",
      "5.325\n",
      "F2\n",
      "1.0\n",
      "F3\n",
      "1.485\n",
      "F4\n",
      "1.5\n",
      "OneClassSVM 0 1\n",
      "X_TEST\n",
      "35391 36000\n",
      "98.30833333333334\n",
      "NORMAL_2\n",
      "19679 20000\n",
      "98.395\n",
      "F1\n",
      "3.73\n",
      "F2\n",
      "1.0\n",
      "F3\n",
      "1.385\n",
      "F4\n",
      "1.01\n"
     ]
    }
   ],
   "source": [
    "log = None\n",
    "if FLUSH_FILE:\n",
    "    log = open(PATH_OUTPUTS+OUTPUT_FILE_NAME, \"a\", buffering=1)\n",
    "\n",
    "hst = []\n",
    "for nu in ocsvm_river_p['nu']:\n",
    "    print('.', end='')\n",
    "    clf = anomaly.OneClassSVM(nu=nu)\n",
    "\n",
    "    for x in X_train:\n",
    "        clf.learn_one(numpy2dict(x))\n",
    "\n",
    "    for t in ocsvm_river_p['threshold']:\n",
    "        print(clf, nu, t, file=log)\n",
    "\n",
    "        print('X_TEST', file=log)\n",
    "        verify_inliers(calculate_score(clf, X_test), t)\n",
    "        print('NORMAL_2', file=log)\n",
    "        verify_inliers(calculate_score(clf, data_ds3_t2_normal[:LIMITADOR, :-1]), t)\n",
    "        print('F1', file=log)\n",
    "        verify_outliers(calculate_score(clf, data_ds3_fault1[:LIMITADOR, :-1]), t)\n",
    "        print('F2', file=log)\n",
    "        verify_outliers(calculate_score(clf, data_ds3_fault2[:LIMITADOR, :-1]), t)\n",
    "        print('F3', file=log)\n",
    "        verify_outliers(calculate_score(clf, data_ds3_fault3[:LIMITADOR, :-1]), t)\n",
    "        print('F4', file=log)\n",
    "        verify_outliers(calculate_score(clf, data_ds3_fault4[:LIMITADOR, :-1]), t)\n",
    "\n",
    "if FLUSH_FILE:\n",
    "    log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3477089912185524\n",
      "0.5241899919893402\n"
     ]
    }
   ],
   "source": [
    "scores = calculate_score(clf, X_test)\n",
    "scores_np = np.array(scores)\n",
    "\n",
    "print(np.mean(scores_np))\n",
    "print(np.std(scores_np, ddof=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5131354875516229\n",
      "0.6982624170706523\n"
     ]
    }
   ],
   "source": [
    "scores1 = calculate_score(clf, data_ds3_fault1)\n",
    "scores_np_1 = np.array(scores1)\n",
    "\n",
    "print(np.mean(scores_np_1))\n",
    "print(np.std(scores_np_1, ddof=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.470196985372892\n",
      "0.8943082724282202\n"
     ]
    }
   ],
   "source": [
    "scores2 = calculate_score(clf, data_ds3_fault2)\n",
    "scores_np_2 = np.array(scores2)\n",
    "\n",
    "print(np.mean(scores_np_2))\n",
    "print(np.std(scores_np_2, ddof=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.048763771243762466\n",
      "0.49472522536601876\n"
     ]
    }
   ],
   "source": [
    "scores3 = calculate_score(clf, data_ds3_fault3)\n",
    "scores_np_3 = np.array(scores3)\n",
    "\n",
    "print(np.mean(scores_np_3))\n",
    "print(np.std(scores_np_3, ddof=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.15687723758574412\n",
      "0.7409306674752314\n"
     ]
    }
   ],
   "source": [
    "scores4 = calculate_score(clf, data_ds3_fault4)\n",
    "scores_np_4 = np.array(scores4)\n",
    "\n",
    "print(np.mean(scores_np_4))\n",
    "print(np.std(scores_np_4, ddof=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "x = np.random.normal(size=1000)\n",
    "plt.hist(scores4, density=True, bins=100)  # `density=False` would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}